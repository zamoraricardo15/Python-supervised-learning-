{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tarea 3\n",
    "#Métodos Supervisados con Python\n",
    "#Ricardo Zamora Mennigke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta 1: [40 puntos] En este ejercicio usaremos los datos (voces.csv). Se trata de un problema de reconocimiento de g´enero mediante el an´alisis de la voz y el habla. Esta base de datos fue creada para identificar una voz como masculina o femenina, bas´andose en las propiedades ac´usticas de la voz y el habla. El conjunto de datos consta de 3.168 muestras de voz grabadas, recogidas de hablantes masculinos y femeninos. El conjunto de datos tiene las siguientes propiedades ac´usticas (variables) de cada voz:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cargue la tabla de datos voces.csv en Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas import DataFrame\n",
    "from matplotlib import colors as mcolors\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rzamoram\\Documents\\Machine Learning\\Métodos Supervisados con Python\\Clase 01\n",
      "(3168, 21)\n",
      "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
      "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
      "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
      "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
      "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
      "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
      "\n",
      "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
      "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
      "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
      "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
      "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
      "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
      "\n",
      "     maxfun   meandom    mindom    maxdom   dfrange   modindx     genero  \n",
      "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000  Masculino  \n",
      "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632  Masculino  \n",
      "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512  Masculino  \n",
      "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119  Masculino  \n",
      "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274  Masculino  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  genero    3168 non-null   object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "pasada = os.getcwd()\n",
    "os.chdir(\"C:/Users/rzamoram/Documents/Machine Learning/Métodos Supervisados con Python/Clase 01\")\n",
    "print(os.getcwd())\n",
    "datos = pd.read_csv('voces.csv',delimiter=',',decimal=\".\")\n",
    "print(datos.shape)\n",
    "print(datos.head())\n",
    "print(datos.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.180907</td>\n",
       "      <td>0.057126</td>\n",
       "      <td>0.185621</td>\n",
       "      <td>0.140456</td>\n",
       "      <td>0.224765</td>\n",
       "      <td>0.084309</td>\n",
       "      <td>3.140168</td>\n",
       "      <td>36.568461</td>\n",
       "      <td>0.895127</td>\n",
       "      <td>0.408216</td>\n",
       "      <td>0.165282</td>\n",
       "      <td>0.180907</td>\n",
       "      <td>0.142807</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>0.258842</td>\n",
       "      <td>0.829211</td>\n",
       "      <td>0.052647</td>\n",
       "      <td>5.047277</td>\n",
       "      <td>4.994630</td>\n",
       "      <td>0.173752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.016652</td>\n",
       "      <td>0.036360</td>\n",
       "      <td>0.048680</td>\n",
       "      <td>0.023639</td>\n",
       "      <td>0.042783</td>\n",
       "      <td>4.240529</td>\n",
       "      <td>134.928661</td>\n",
       "      <td>0.044980</td>\n",
       "      <td>0.177521</td>\n",
       "      <td>0.077203</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.030077</td>\n",
       "      <td>0.525205</td>\n",
       "      <td>0.063299</td>\n",
       "      <td>3.521157</td>\n",
       "      <td>3.520039</td>\n",
       "      <td>0.119454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.018363</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.042946</td>\n",
       "      <td>0.014558</td>\n",
       "      <td>0.141735</td>\n",
       "      <td>2.068455</td>\n",
       "      <td>0.738651</td>\n",
       "      <td>0.036876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.055565</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.103093</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.163662</td>\n",
       "      <td>0.041954</td>\n",
       "      <td>0.169593</td>\n",
       "      <td>0.111087</td>\n",
       "      <td>0.208747</td>\n",
       "      <td>0.042560</td>\n",
       "      <td>1.649569</td>\n",
       "      <td>5.669547</td>\n",
       "      <td>0.861811</td>\n",
       "      <td>0.258041</td>\n",
       "      <td>0.118016</td>\n",
       "      <td>0.163662</td>\n",
       "      <td>0.116998</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.419828</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.070312</td>\n",
       "      <td>2.044922</td>\n",
       "      <td>0.099766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.059155</td>\n",
       "      <td>0.190032</td>\n",
       "      <td>0.140286</td>\n",
       "      <td>0.225684</td>\n",
       "      <td>0.094280</td>\n",
       "      <td>2.197101</td>\n",
       "      <td>8.318463</td>\n",
       "      <td>0.901767</td>\n",
       "      <td>0.396335</td>\n",
       "      <td>0.186599</td>\n",
       "      <td>0.184838</td>\n",
       "      <td>0.140519</td>\n",
       "      <td>0.046110</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.765795</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>4.992188</td>\n",
       "      <td>4.945312</td>\n",
       "      <td>0.139357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.067020</td>\n",
       "      <td>0.210618</td>\n",
       "      <td>0.175939</td>\n",
       "      <td>0.243660</td>\n",
       "      <td>0.114175</td>\n",
       "      <td>2.931694</td>\n",
       "      <td>13.648905</td>\n",
       "      <td>0.928713</td>\n",
       "      <td>0.533676</td>\n",
       "      <td>0.221104</td>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.169581</td>\n",
       "      <td>0.047904</td>\n",
       "      <td>0.277457</td>\n",
       "      <td>1.177166</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>7.007812</td>\n",
       "      <td>6.992188</td>\n",
       "      <td>0.209183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.251124</td>\n",
       "      <td>0.115273</td>\n",
       "      <td>0.261224</td>\n",
       "      <td>0.247347</td>\n",
       "      <td>0.273469</td>\n",
       "      <td>0.252225</td>\n",
       "      <td>34.725453</td>\n",
       "      <td>1309.612887</td>\n",
       "      <td>0.981997</td>\n",
       "      <td>0.842936</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.251124</td>\n",
       "      <td>0.237636</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.279114</td>\n",
       "      <td>2.957682</td>\n",
       "      <td>0.458984</td>\n",
       "      <td>21.867188</td>\n",
       "      <td>21.843750</td>\n",
       "      <td>0.932374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          meanfreq           sd       median          Q25          Q75  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.180907     0.057126     0.185621     0.140456     0.224765   \n",
       "std       0.029918     0.016652     0.036360     0.048680     0.023639   \n",
       "min       0.039363     0.018363     0.010975     0.000229     0.042946   \n",
       "25%       0.163662     0.041954     0.169593     0.111087     0.208747   \n",
       "50%       0.184838     0.059155     0.190032     0.140286     0.225684   \n",
       "75%       0.199146     0.067020     0.210618     0.175939     0.243660   \n",
       "max       0.251124     0.115273     0.261224     0.247347     0.273469   \n",
       "\n",
       "               IQR         skew         kurt       sp.ent          sfm  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.084309     3.140168    36.568461     0.895127     0.408216   \n",
       "std       0.042783     4.240529   134.928661     0.044980     0.177521   \n",
       "min       0.014558     0.141735     2.068455     0.738651     0.036876   \n",
       "25%       0.042560     1.649569     5.669547     0.861811     0.258041   \n",
       "50%       0.094280     2.197101     8.318463     0.901767     0.396335   \n",
       "75%       0.114175     2.931694    13.648905     0.928713     0.533676   \n",
       "max       0.252225    34.725453  1309.612887     0.981997     0.842936   \n",
       "\n",
       "              mode     centroid      meanfun       minfun       maxfun  \\\n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000   \n",
       "mean      0.165282     0.180907     0.142807     0.036802     0.258842   \n",
       "std       0.077203     0.029918     0.032304     0.019220     0.030077   \n",
       "min       0.000000     0.039363     0.055565     0.009775     0.103093   \n",
       "25%       0.118016     0.163662     0.116998     0.018223     0.253968   \n",
       "50%       0.186599     0.184838     0.140519     0.046110     0.271186   \n",
       "75%       0.221104     0.199146     0.169581     0.047904     0.277457   \n",
       "max       0.280000     0.251124     0.237636     0.204082     0.279114   \n",
       "\n",
       "           meandom       mindom       maxdom      dfrange      modindx  \n",
       "count  3168.000000  3168.000000  3168.000000  3168.000000  3168.000000  \n",
       "mean      0.829211     0.052647     5.047277     4.994630     0.173752  \n",
       "std       0.525205     0.063299     3.521157     3.520039     0.119454  \n",
       "min       0.007812     0.004883     0.007812     0.000000     0.000000  \n",
       "25%       0.419828     0.007812     2.070312     2.044922     0.099766  \n",
       "50%       0.765795     0.023438     4.992188     4.945312     0.139357  \n",
       "75%       1.177166     0.070312     7.007812     6.992188     0.209183  \n",
       "max       2.957682     0.458984    21.867188    21.843750     0.932374  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.describe(include = np.number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribucion_variable_predecir(data:DataFrame,variable_predict:str):\n",
    "    colors = list(dict(**mcolors.CSS4_COLORS))\n",
    "    df = pd.crosstab(index=data[variable_predict],columns=\"valor\") / data[variable_predict].count()\n",
    "    fig = plt.figure(figsize=(10,9))\n",
    "    g = fig.add_subplot(111)\n",
    "    countv = 0\n",
    "    titulo = \"Distribución de la variable %s\" % variable_predict\n",
    "    for i in range(df.shape[0]):\n",
    "        g.barh(1,df.iloc[i],left = countv, align='center',color=colors[11+i],label= df.iloc[i].name)\n",
    "        countv = countv + df.iloc[i]\n",
    "    vals = g.get_xticks()\n",
    "    g.set_xlim(0,1)\n",
    "    g.set_yticklabels(\"\")\n",
    "    g.set_title(titulo)\n",
    "    g.set_ylabel(variable_predict)\n",
    "    g.set_xticklabels(['{:.0%}'.format(x) for x in vals])\n",
    "    countv = 0 \n",
    "    for v in df.iloc[:,0]:\n",
    "        g.text(np.mean([countv,countv+v]) - 0.03, 1 , '{:.1%}'.format(v), color='black', fontweight='bold')\n",
    "        countv = countv + v\n",
    "    g.legend(loc='upper center', bbox_to_anchor=(1.08, 1), shadow=True, ncol=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distribucion_variable_predecir(datos,\"genero\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problema equilibrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_general(MC, nombres = None):\n",
    "    precision_global = np.sum(MC.diagonal()) / np.sum(MC)\n",
    "    error_global = 1 - precision_global\n",
    "    precision_categoria  = pd.DataFrame(MC.diagonal()/np.sum(MC,axis = 1)).T\n",
    "    if nombres!=None:\n",
    "        precision_categoria.columns = nombres\n",
    "    return {\"Matriz de Confusión\":MC, \n",
    "            \"Precisión Global\":precision_global, \n",
    "            \"Error Global\":error_global, \n",
    "            \"Precisión por categoría\":precision_categoria}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poder_predictivo_categorica(data:DataFrame, var:str, variable_predict:str):\n",
    "    df = pd.crosstab(index= data[var],columns=data[variable_predict])\n",
    "    df = df.div(df.sum(axis=1),axis=0)\n",
    "    titulo = \"Distribución de la variable %s según la variable %s\" % (var,variable_predict)\n",
    "    g = df.plot(kind='barh',stacked=True,legend = True, figsize = (10,9), \\\n",
    "                xlim = (0,1),title = titulo, width = 0.8)\n",
    "    vals = g.get_xticks()\n",
    "    g.set_xticklabels(['{:.0%}'.format(x) for x in vals])\n",
    "    g.legend(loc='upper center', bbox_to_anchor=(1.08, 1), shadow=True, ncol=1)\n",
    "    for bars in g.containers:\n",
    "        plt.setp(bars, width=.9)\n",
    "    for i in range(df.shape[0]):\n",
    "        countv = 0 \n",
    "        for v in df.iloc[i]:\n",
    "            g.text(np.mean([countv,countv+v]) - 0.03, i , '{:.1%}'.format(v), color='black', fontweight='bold')\n",
    "            countv = countv + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poder_predictivo_numerica(data:DataFrame, var:str, variable_predict:str):\n",
    "    sns.FacetGrid(data, hue=variable_predict, height=6).map(sns.kdeplot, var, shade=True).add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use Bosques Aleatorios, ADABoosting y XGBoosting en Python (con los par´ametros por defecto) para generar un modelo predictivo para la tabla voces.csv usando el 80 % de los datos para la tabla aprendizaje y un 20 % para la tabla testing, luego calcule para los datos de testing la matriz de confusi´on, la precisi´on global y la precisi´on para cada una de las dos categor´ıas. ¿Son buenos los resultados? Explique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
      "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
      "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
      "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
      "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
      "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
      "\n",
      "          kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \\\n",
      "0   274.402906  0.893369  0.491918  0.000000  0.059781  0.084279  0.015702   \n",
      "1   634.613855  0.892193  0.513724  0.000000  0.066009  0.107937  0.015826   \n",
      "2  1024.927705  0.846389  0.478905  0.000000  0.077316  0.098706  0.015656   \n",
      "3     4.177296  0.963322  0.727232  0.083878  0.151228  0.088965  0.017798   \n",
      "4     4.333713  0.971955  0.783568  0.104261  0.135120  0.106398  0.016931   \n",
      "\n",
      "     maxfun   meandom    mindom    maxdom   dfrange   modindx  \n",
      "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000  \n",
      "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632  \n",
      "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512  \n",
      "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119  \n",
      "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274  \n",
      "      genero\n",
      "0  Masculino\n",
      "1  Masculino\n",
      "2  Masculino\n",
      "3  Masculino\n",
      "4  Masculino\n"
     ]
    }
   ],
   "source": [
    "X = datos.iloc[:,:20] \n",
    "print(X.head())\n",
    "y = datos.iloc[:,20:21] \n",
    "print(y.head())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones en Testing son: ['Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino']\n"
     ]
    }
   ],
   "source": [
    "##Bosques\n",
    "instancia_bosque = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "\n",
    "instancia_bosque.fit(X_train,y_train.iloc[:,0].values)\n",
    "\n",
    "print(\"Las predicciones en Testing son: {}\".format(instancia_bosque.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[297   4]\n",
      " [  8 325]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9810725552050473\n",
      "\n",
      "Error Global:\n",
      "0.018927444794952675\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.986711   0.975976\n"
     ]
    }
   ],
   "source": [
    "prediccion = instancia_bosque.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01925904 0.11782454 0.00791809 0.1597916  0.01179789 0.15810167\n",
      " 0.00646906 0.0086625  0.0367269  0.01307909 0.01046183 0.02314109\n",
      " 0.36042914 0.00893751 0.00706416 0.00603186 0.01916278 0.01209636\n",
      " 0.00571099 0.00733391]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x1ff891ca488>,\n",
       "  <matplotlib.axis.YTick at 0x1ff891c6748>,\n",
       "  <matplotlib.axis.YTick at 0x1ff891484c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8921f208>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8921f848>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8921f4c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff892235c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89223ec8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89229488>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89229bc8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8922e408>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8922ebc8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff892329c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff892374c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89232848>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89237ac8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8923b288>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8923bbc8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8923e748>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89241248>],\n",
       " <a list of 20 Text yticklabel objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importancia = instancia_bosque.feature_importances_\n",
    "print(importancia)\n",
    "etiquetas = X_train.columns.values\n",
    "y_pos = np.arange(len(etiquetas))\n",
    "plt.barh(y_pos, importancia, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones en Testing son: ['Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino']\n"
     ]
    }
   ],
   "source": [
    "###XGBoosting\n",
    "instancia_potenciacion = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "print(\"Las predicciones en Testing son: {}\".format(instancia_potenciacion.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[293   8]\n",
      " [  6 327]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9779179810725552\n",
      "\n",
      "Error Global:\n",
      "0.02208201892744477\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.973422   0.981982\n"
     ]
    }
   ],
   "source": [
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 1.65693205e-03 0.00000000e+00 1.05010633e-03\n",
      " 5.44828510e-03 4.34151977e-02 0.00000000e+00 0.00000000e+00\n",
      " 7.56876857e-04 5.06176267e-03 0.00000000e+00 1.52440581e-04\n",
      " 9.37937428e-01 4.21144875e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.09522147e-04]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x1ff89299248>,\n",
       "  <matplotlib.axis.YTick at 0x1ff892974c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff891f0f08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff892f2288>,\n",
       "  <matplotlib.axis.YTick at 0x1ff892f2688>,\n",
       "  <matplotlib.axis.YTick at 0x1ff892f2d08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff892f7348>,\n",
       "  <matplotlib.axis.YTick at 0x1ff892f7b08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff892fc308>,\n",
       "  <matplotlib.axis.YTick at 0x1ff892fccc8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89301788>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89306308>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89306e48>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8930a9c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89301888>,\n",
       "  <matplotlib.axis.YTick at 0x1ff892f79c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8930eb08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89310508>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89313188>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89313c08>],\n",
       " <a list of 20 Text yticklabel objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importancia = instancia_potenciacion.feature_importances_\n",
    "print(importancia)\n",
    "etiquetas = X_train.columns.values\n",
    "y_pos = np.arange(len(etiquetas))\n",
    "plt.barh(y_pos, importancia, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones en Testing son: ['Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Femenino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Femenino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino' 'Masculino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Femenino'\n",
      " 'Femenino' 'Femenino' 'Femenino' 'Masculino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Femenino'\n",
      " 'Masculino' 'Masculino' 'Masculino' 'Femenino' 'Masculino' 'Masculino'\n",
      " 'Femenino' 'Masculino' 'Femenino' 'Femenino']\n"
     ]
    }
   ],
   "source": [
    "###ADA Boosting\n",
    "instancia_potenciacion = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "print(\"Las predicciones en Testing son: {}\".format(instancia_potenciacion.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[283  18]\n",
      " [  4 329]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9652996845425867\n",
      "\n",
      "Error Global:\n",
      "0.034700315457413256\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.940199   0.987988\n"
     ]
    }
   ],
   "source": [
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.1 0.  0.  0.  0.2 0.  0.  0.  0.1 0.  0.  0.4 0.1 0.  0.  0.  0.1\n",
      " 0.  0. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x1ff89357dc8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89344088>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89356b08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8957bc08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8957e288>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8957ea08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89584248>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8957e4c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89584bc8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff895883c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89588c88>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8958d888>,\n",
       "  <matplotlib.axis.YTick at 0x1ff895913c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89591dc8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89594a88>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89598608>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89591e08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89588f08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8959b6c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8959f0c8>],\n",
       " <a list of 20 Text yticklabel objects>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importancia = instancia_potenciacion.feature_importances_\n",
    "print(importancia)\n",
    "etiquetas = X_train.columns.values\n",
    "y_pos = np.arange(len(etiquetas))\n",
    "plt.barh(y_pos, importancia, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, etiquetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son muy buenos, en el caso de bosques se tiene un Precisión Global de 0.9810725552050473, y en cada categoria se tiene una precision tambien muy alta en Femenino es 0.986711 y Masculino es 0.975976. De la misma manera XGBoosting tiene una Precisión Global alta, no tanto, como bosques, pero elevada de 0.9779179810725552, y parecido a bosques por categoria Femenino 0.973422 y Masculino 0.981982. ADA finalmente muestra la precision mas baja pero sigue teniendo excelentes reusltados con una Precisión Global de 0.9652996845425867 y por categoria de Femenino 0.940199 y  Masculino 0.987988."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Usando la funci´on programada en el ejercicio 1 de la tarea anterior, los datos voces.csv y los modelos generados arriba construya un DataFrame de manera que en cada una de las filas aparezca un modelo predictivo y en las columnas aparezcan los ´ındices Precisi´on Global, Error Global Precisi´on Positiva (PP), Precisi´on Negativa (PN), Falsos Positivos (FP), los Falsos Negativos (FN), la Asertividad Positiva (AP) y la Asertividad Negativa (AN). ¿Cu´al de los modelos es mejor para estos datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_general_extra(MC, nombres = None):\n",
    "    precision_global = np.sum(MC.diagonal()) / np.sum(MC)\n",
    "    error_global = 1 - precision_global\n",
    "    precision_categoria  = pd.DataFrame(MC.diagonal()/np.sum(MC,axis = 1)).T\n",
    "    precision_positiva = MC[1][1]/(MC[1][1] + MC[1][0])\n",
    "    precision_negativa = MC[0][0]/(MC[0][0] + MC[0][1])\n",
    "    falsos_positivos = 1 - precision_negativa\n",
    "    falsos_negativos = 1 - precision_positiva\n",
    "    asertividad_positiva = MC[1][1]/(MC[0][1] + MC[1][1])\n",
    "    asertividad_negativa = MC[0][0]/(MC[0][0] + MC[1][0])\n",
    "    if nombres!=None:\n",
    "        precision_categoria.columns = nombres\n",
    "    return {\"Matriz de Confusión\":MC, \n",
    "            \"Precisión Global\":precision_global, \n",
    "            \"Error Global\":error_global, \n",
    "            \"Precisión por categoría\":precision_categoria,\n",
    "            \"Precision Positiva (PP)\": precision_positiva, \n",
    "            \"Precision Negativa (PN)\":precision_negativa, \n",
    "            \"Falsos Positivos(FP)\": falsos_positivos,\n",
    "            \"Falsos Negativos (FN)\": falsos_negativos,\n",
    "            \"Asertividad Positiva (AP)\": asertividad_positiva,\n",
    "            \"Asertividad Negativa (NP)\": asertividad_negativa}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[297   4]\n",
      " [  8 325]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9810725552050473\n",
      "\n",
      "Error Global:\n",
      "0.018927444794952675\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.986711   0.975976\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.975975975975976\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9867109634551495\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.013289036544850474\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.024024024024024038\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9878419452887538\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9737704918032787\n"
     ]
    }
   ],
   "source": [
    "##Bosques\n",
    "instancia_bosque = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "instancia_bosque.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_bosque.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[293   8]\n",
      " [  6 327]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9779179810725552\n",
      "\n",
      "Error Global:\n",
      "0.02208201892744477\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.973422   0.981982\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9819819819819819\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.973421926910299\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.02657807308970095\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.018018018018018056\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9761194029850746\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.979933110367893\n"
     ]
    }
   ],
   "source": [
    "###XGBoosting\n",
    "instancia_potenciacion = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[283  18]\n",
      " [  4 329]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9652996845425867\n",
      "\n",
      "Error Global:\n",
      "0.034700315457413256\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.940199   0.987988\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.987987987987988\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9401993355481728\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.05980066445182719\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.012012012012011963\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9481268011527377\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9860627177700348\n"
     ]
    }
   ],
   "source": [
    "###ADA Boosting\n",
    "instancia_potenciacion = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precisi´on Global</th>\n",
       "      <th>Error Global</th>\n",
       "      <th>Precisi´on Positiva (PP)</th>\n",
       "      <th>Precisi´on Negativa (PN)</th>\n",
       "      <th>Falsos Positivos (FP)</th>\n",
       "      <th>Falsos Negativos (FN)</th>\n",
       "      <th>Asertividad Positiva (AP)</th>\n",
       "      <th>Asertividad Negativa (AN)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K-vecinos todas variables</th>\n",
       "      <td>0.741325</td>\n",
       "      <td>0.258675</td>\n",
       "      <td>0.771772</td>\n",
       "      <td>0.707641</td>\n",
       "      <td>0.292359</td>\n",
       "      <td>0.228228</td>\n",
       "      <td>0.744928</td>\n",
       "      <td>0.737024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-vecinos 6 variables</th>\n",
       "      <td>0.979495</td>\n",
       "      <td>0.020505</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.983389</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision (default)</th>\n",
       "      <td>0.960568</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>0.956811</td>\n",
       "      <td>0.043189</td>\n",
       "      <td>0.036036</td>\n",
       "      <td>0.961078</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision (criterion='entropy',max_depth=2)</th>\n",
       "      <td>0.944795</td>\n",
       "      <td>0.055205</td>\n",
       "      <td>0.948949</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.051051</td>\n",
       "      <td>0.946108</td>\n",
       "      <td>0.943333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision (criterion='gini', splitter='random', max_depth=3)</th>\n",
       "      <td>0.900631</td>\n",
       "      <td>0.099369</td>\n",
       "      <td>0.951952</td>\n",
       "      <td>0.843854</td>\n",
       "      <td>0.156146</td>\n",
       "      <td>0.048048</td>\n",
       "      <td>0.870879</td>\n",
       "      <td>0.940741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision 6 predictoras (default)</th>\n",
       "      <td>0.966877</td>\n",
       "      <td>0.033123</td>\n",
       "      <td>0.960961</td>\n",
       "      <td>0.973422</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.039039</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.957516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision 6 predictoras (criterion='entropy',max_depth=2)</th>\n",
       "      <td>0.944795</td>\n",
       "      <td>0.055205</td>\n",
       "      <td>0.948949</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.051051</td>\n",
       "      <td>0.946108</td>\n",
       "      <td>0.943333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision 6 predictoras (criterion='gini', splitter='random', max_depth=3)</th>\n",
       "      <td>0.916404</td>\n",
       "      <td>0.083596</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosques</th>\n",
       "      <td>0.981073</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.986711</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.987842</td>\n",
       "      <td>0.973770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting</th>\n",
       "      <td>0.977918</td>\n",
       "      <td>0.022082</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>0.973422</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.976119</td>\n",
       "      <td>0.979933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA Boosting</th>\n",
       "      <td>0.965300</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.948127</td>\n",
       "      <td>0.986063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Precisi´on Global  \\\n",
       "K-vecinos todas variables                                    0.741325   \n",
       "K-vecinos 6 variables                                        0.979495   \n",
       "Arbol de Decision (default)                                  0.960568   \n",
       "Arbol de Decision (criterion='entropy',max_dept...           0.944795   \n",
       "Arbol de Decision (criterion='gini', splitter='...           0.900631   \n",
       "Arbol de Decision 6 predictoras (default)                    0.966877   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...           0.944795   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...           0.916404   \n",
       "Bosques                                                      0.981073   \n",
       "XGBoosting                                                   0.977918   \n",
       "ADA Boosting                                                 0.965300   \n",
       "\n",
       "                                                    Error Global  \\\n",
       "K-vecinos todas variables                               0.258675   \n",
       "K-vecinos 6 variables                                   0.020505   \n",
       "Arbol de Decision (default)                             0.039432   \n",
       "Arbol de Decision (criterion='entropy',max_dept...      0.055205   \n",
       "Arbol de Decision (criterion='gini', splitter='...      0.099369   \n",
       "Arbol de Decision 6 predictoras (default)               0.033123   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...      0.055205   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...      0.083596   \n",
       "Bosques                                                 0.018927   \n",
       "XGBoosting                                              0.022082   \n",
       "ADA Boosting                                            0.034700   \n",
       "\n",
       "                                                    Precisi´on Positiva (PP)  \\\n",
       "K-vecinos todas variables                                           0.771772   \n",
       "K-vecinos 6 variables                                               0.975976   \n",
       "Arbol de Decision (default)                                         0.963964   \n",
       "Arbol de Decision (criterion='entropy',max_dept...                  0.948949   \n",
       "Arbol de Decision (criterion='gini', splitter='...                  0.951952   \n",
       "Arbol de Decision 6 predictoras (default)                           0.960961   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...                  0.948949   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...                  0.987988   \n",
       "Bosques                                                             0.975976   \n",
       "XGBoosting                                                          0.981982   \n",
       "ADA Boosting                                                        0.987988   \n",
       "\n",
       "                                                    Precisi´on Negativa (PN)  \\\n",
       "K-vecinos todas variables                                           0.707641   \n",
       "K-vecinos 6 variables                                               0.983389   \n",
       "Arbol de Decision (default)                                         0.956811   \n",
       "Arbol de Decision (criterion='entropy',max_dept...                  0.940199   \n",
       "Arbol de Decision (criterion='gini', splitter='...                  0.843854   \n",
       "Arbol de Decision 6 predictoras (default)                           0.973422   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...                  0.940199   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...                  0.837209   \n",
       "Bosques                                                             0.986711   \n",
       "XGBoosting                                                          0.973422   \n",
       "ADA Boosting                                                        0.940199   \n",
       "\n",
       "                                                    Falsos Positivos (FP)  \\\n",
       "K-vecinos todas variables                                        0.292359   \n",
       "K-vecinos 6 variables                                            0.016611   \n",
       "Arbol de Decision (default)                                      0.043189   \n",
       "Arbol de Decision (criterion='entropy',max_dept...               0.059801   \n",
       "Arbol de Decision (criterion='gini', splitter='...               0.156146   \n",
       "Arbol de Decision 6 predictoras (default)                        0.026578   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...               0.059801   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...               0.162791   \n",
       "Bosques                                                          0.013289   \n",
       "XGBoosting                                                       0.026578   \n",
       "ADA Boosting                                                     0.059801   \n",
       "\n",
       "                                                    Falsos Negativos (FN)  \\\n",
       "K-vecinos todas variables                                        0.228228   \n",
       "K-vecinos 6 variables                                            0.024024   \n",
       "Arbol de Decision (default)                                      0.036036   \n",
       "Arbol de Decision (criterion='entropy',max_dept...               0.051051   \n",
       "Arbol de Decision (criterion='gini', splitter='...               0.048048   \n",
       "Arbol de Decision 6 predictoras (default)                        0.039039   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...               0.051051   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...               0.012012   \n",
       "Bosques                                                          0.024024   \n",
       "XGBoosting                                                       0.018018   \n",
       "ADA Boosting                                                     0.012012   \n",
       "\n",
       "                                                    Asertividad Positiva (AP)  \\\n",
       "K-vecinos todas variables                                            0.744928   \n",
       "K-vecinos 6 variables                                                0.984848   \n",
       "Arbol de Decision (default)                                          0.961078   \n",
       "Arbol de Decision (criterion='entropy',max_dept...                   0.946108   \n",
       "Arbol de Decision (criterion='gini', splitter='...                   0.870879   \n",
       "Arbol de Decision 6 predictoras (default)                            0.975610   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...                   0.946108   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...                   0.870370   \n",
       "Bosques                                                              0.987842   \n",
       "XGBoosting                                                           0.976119   \n",
       "ADA Boosting                                                         0.948127   \n",
       "\n",
       "                                                    Asertividad Negativa (AN)  \n",
       "K-vecinos todas variables                                            0.737024  \n",
       "K-vecinos 6 variables                                                0.973684  \n",
       "Arbol de Decision (default)                                          0.960000  \n",
       "Arbol de Decision (criterion='entropy',max_dept...                   0.943333  \n",
       "Arbol de Decision (criterion='gini', splitter='...                   0.940741  \n",
       "Arbol de Decision 6 predictoras (default)                            0.957516  \n",
       "Arbol de Decision 6 predictoras (criterion='ent...                   0.943333  \n",
       "Arbol de Decision 6 predictoras (criterion='gin...                   0.984375  \n",
       "Bosques                                                              0.973770  \n",
       "XGBoosting                                                           0.979933  \n",
       "ADA Boosting                                                         0.986063  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.matrix([[0.7413249211356467, 0.25867507886435326, 0.7717717717717718, 0.707641196013289, 0.292358803986711, 0.2282282282282282, 0.744927536231884, 0.7370242214532872],\n",
    "               [0.9794952681388013, 0.02050473186119872, 0.975975975975976, 0.9833887043189369, 0.01661129568106312, 0.024024024024024038, 0.9848484848484849, 0.9736842105263158],\n",
    "              [0.9605678233438486, 0.039432176656151396, 0.963963963963964, 0.9568106312292359, 0.04318936877076407, 0.036036036036036, 0.9610778443113772, 0.96],\n",
    "              [0.944794952681388, 0.05520504731861198, 0.948948948948949, 0.9401993355481728, 0.05980066445182719, 0.05105105105105101, 0.9461077844311377, 0.9433333333333334],\n",
    "              [0.9006309148264984, 0.09936908517350163, 0.9519519519519519, 0.8438538205980066, 0.15614617940199338, 0.048048048048048075, 0.8708791208791209, 0.9407407407407408],\n",
    "              [0.9668769716088328, 0.03312302839116721, 0.960960960960961, 0.973421926910299, 0.02657807308970095, 0.03903903903903905, 0.975609756097561, 0.9575163398692811],\n",
    "              [0.944794952681388, 0.05520504731861198, 0.948948948948949, 0.9401993355481728, 0.05980066445182719, 0.05105105105105101, 0.9461077844311377, 0.9433333333333334],\n",
    "              [0.916403785488959, 0.08359621451104104, 0.987987987987988, 0.8372093023255814, 0.16279069767441856, 0.012012012012011963, 0.8703703703703703, 0.984375],\n",
    "              [0.9810725552050473, 0.018927444794952675, 0.975975975975976, 0.9867109634551495, 0.013289036544850474, 0.024024024024024038, 0.9878419452887538, 0.9737704918032787],\n",
    "              [0.9779179810725552, 0.02208201892744477, 0.9819819819819819, 0.973421926910299, 0.02657807308970095, 0.018018018018018056, 0.9761194029850746, 0.979933110367893],\n",
    "              [0.9652996845425867, 0.034700315457413256, 0.987987987987988, 0.9401993355481728, 0.05980066445182719, 0.012012012012011963, 0.9481268011527377, 0.9860627177700348]])\n",
    "mi_df = pd.DataFrame(A)\n",
    "nombres_filas = [\"K-vecinos todas variables\",\"K-vecinos 6 variables\",\"Arbol de Decision (default)\",\"Arbol de Decision (criterion='entropy',max_depth=2)\",\"Arbol de Decision (criterion='gini', splitter='random', max_depth=3)\",\"Arbol de Decision 6 predictoras (default)\",\"Arbol de Decision 6 predictoras (criterion='entropy',max_depth=2)\",\"Arbol de Decision 6 predictoras (criterion='gini', splitter='random', max_depth=3)\", \"Bosques\", \"XGBoosting\", \"ADA Boosting\"]\n",
    "nombres_columnas = [\"Precisi´on Global\",\"Error Global\",\"Precisi´on Positiva (PP)\", \"Precisi´on Negativa (PN)\", \"Falsos Positivos (FP)\", \"Falsos Negativos (FN)\", \"Asertividad Positiva (AP)\", \"Asertividad Negativa (AN)\"]\n",
    "mi_df = pd.DataFrame(A, index = nombres_filas, columns = nombres_columnas )\n",
    "mi_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estos datos se denota aun que todos los metodos en general presentan buenos resultados que los resultados mas precisos son los de bosques aleatorios, su precision global es mas alta, es decir, logra identificar mejor los casos la PP y PN confirman esto, ademas los datos confundidas FP y FN son menores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Repita los ejercicios 1-3, pero esta vez use una combinaci´on diferente de los par´ametros de los m´etodos. ¿Mejora la predicci´on?."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, ya que es una parte mas exploratoria, para comparar estos metodos se establece n_estimators=7, max_depth=2, random_state=0, esto con el fin de limitar significativamente el accionar del algoritmo y limitar a pocos estimadores y una profundidad limitada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[280  21]\n",
      " [  8 325]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9542586750788643\n",
      "\n",
      "Error Global:\n",
      "0.045741324921135695\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.930233   0.975976\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.975975975975976\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9302325581395349\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.06976744186046513\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.024024024024024038\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9393063583815029\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "##Bosques\n",
    "instancia_bosque = RandomForestClassifier(n_estimators=7, max_depth=2, random_state=0)\n",
    "instancia_bosque.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_bosque.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[296   5]\n",
      " [ 19 314]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9621451104100947\n",
      "\n",
      "Error Global:\n",
      "0.03785488958990535\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.983389   0.942943\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9429429429429429\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9833887043189369\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.01661129568106312\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.0570570570570571\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9843260188087775\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9396825396825397\n"
     ]
    }
   ],
   "source": [
    "###XGBoosting\n",
    "instancia_potenciacion = GradientBoostingClassifier(n_estimators=7, max_depth=2, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[279  22]\n",
      " [  4 329]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9589905362776026\n",
      "\n",
      "Error Global:\n",
      "0.04100946372239744\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0   0.92691   0.987988\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.987987987987988\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9269102990033222\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.07308970099667778\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.012012012012011963\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9373219373219374\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9858657243816255\n"
     ]
    }
   ],
   "source": [
    "###ADA Boosting\n",
    "instancia_potenciacion = AdaBoostClassifier(n_estimators=7, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precisi´on Global</th>\n",
       "      <th>Error Global</th>\n",
       "      <th>Precisi´on Positiva (PP)</th>\n",
       "      <th>Precisi´on Negativa (PN)</th>\n",
       "      <th>Falsos Positivos (FP)</th>\n",
       "      <th>Falsos Negativos (FN)</th>\n",
       "      <th>Asertividad Positiva (AP)</th>\n",
       "      <th>Asertividad Negativa (AN)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K-vecinos todas variables</th>\n",
       "      <td>0.741325</td>\n",
       "      <td>0.258675</td>\n",
       "      <td>0.771772</td>\n",
       "      <td>0.707641</td>\n",
       "      <td>0.292359</td>\n",
       "      <td>0.228228</td>\n",
       "      <td>0.744928</td>\n",
       "      <td>0.737024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-vecinos 6 variables</th>\n",
       "      <td>0.979495</td>\n",
       "      <td>0.020505</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.983389</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision (default)</th>\n",
       "      <td>0.960568</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>0.956811</td>\n",
       "      <td>0.043189</td>\n",
       "      <td>0.036036</td>\n",
       "      <td>0.961078</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision (criterion='entropy',max_depth=2)</th>\n",
       "      <td>0.944795</td>\n",
       "      <td>0.055205</td>\n",
       "      <td>0.948949</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.051051</td>\n",
       "      <td>0.946108</td>\n",
       "      <td>0.943333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision (criterion='gini', splitter='random', max_depth=3)</th>\n",
       "      <td>0.900631</td>\n",
       "      <td>0.099369</td>\n",
       "      <td>0.951952</td>\n",
       "      <td>0.843854</td>\n",
       "      <td>0.156146</td>\n",
       "      <td>0.048048</td>\n",
       "      <td>0.870879</td>\n",
       "      <td>0.940741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision 6 predictoras (default)</th>\n",
       "      <td>0.966877</td>\n",
       "      <td>0.033123</td>\n",
       "      <td>0.960961</td>\n",
       "      <td>0.973422</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.039039</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.957516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision 6 predictoras (criterion='entropy',max_depth=2)</th>\n",
       "      <td>0.944795</td>\n",
       "      <td>0.055205</td>\n",
       "      <td>0.948949</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.051051</td>\n",
       "      <td>0.946108</td>\n",
       "      <td>0.943333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision 6 predictoras (criterion='gini', splitter='random', max_depth=3)</th>\n",
       "      <td>0.916404</td>\n",
       "      <td>0.083596</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosques</th>\n",
       "      <td>0.981073</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.986711</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.987842</td>\n",
       "      <td>0.973770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting</th>\n",
       "      <td>0.977918</td>\n",
       "      <td>0.022082</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>0.973422</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.976119</td>\n",
       "      <td>0.979933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA Boosting</th>\n",
       "      <td>0.965300</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.948127</td>\n",
       "      <td>0.986063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosques (n_estimators=7, max_depth=2, random_state=0)</th>\n",
       "      <td>0.954259</td>\n",
       "      <td>0.045741</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.939306</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting(n_estimators=7, max_depth=2, random_state=0)</th>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.037855</td>\n",
       "      <td>0.942943</td>\n",
       "      <td>0.983389</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.057057</td>\n",
       "      <td>0.984326</td>\n",
       "      <td>0.939683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA Boosting (n_estimators=7, random_state=0)</th>\n",
       "      <td>0.958991</td>\n",
       "      <td>0.041009</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.926910</td>\n",
       "      <td>0.073090</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.937322</td>\n",
       "      <td>0.985866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Precisi´on Global  \\\n",
       "K-vecinos todas variables                                    0.741325   \n",
       "K-vecinos 6 variables                                        0.979495   \n",
       "Arbol de Decision (default)                                  0.960568   \n",
       "Arbol de Decision (criterion='entropy',max_dept...           0.944795   \n",
       "Arbol de Decision (criterion='gini', splitter='...           0.900631   \n",
       "Arbol de Decision 6 predictoras (default)                    0.966877   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...           0.944795   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...           0.916404   \n",
       "Bosques                                                      0.981073   \n",
       "XGBoosting                                                   0.977918   \n",
       "ADA Boosting                                                 0.965300   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...           0.954259   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...           0.962145   \n",
       "ADA Boosting (n_estimators=7, random_state=0)                0.958991   \n",
       "\n",
       "                                                    Error Global  \\\n",
       "K-vecinos todas variables                               0.258675   \n",
       "K-vecinos 6 variables                                   0.020505   \n",
       "Arbol de Decision (default)                             0.039432   \n",
       "Arbol de Decision (criterion='entropy',max_dept...      0.055205   \n",
       "Arbol de Decision (criterion='gini', splitter='...      0.099369   \n",
       "Arbol de Decision 6 predictoras (default)               0.033123   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...      0.055205   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...      0.083596   \n",
       "Bosques                                                 0.018927   \n",
       "XGBoosting                                              0.022082   \n",
       "ADA Boosting                                            0.034700   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...      0.045741   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...      0.037855   \n",
       "ADA Boosting (n_estimators=7, random_state=0)           0.041009   \n",
       "\n",
       "                                                    Precisi´on Positiva (PP)  \\\n",
       "K-vecinos todas variables                                           0.771772   \n",
       "K-vecinos 6 variables                                               0.975976   \n",
       "Arbol de Decision (default)                                         0.963964   \n",
       "Arbol de Decision (criterion='entropy',max_dept...                  0.948949   \n",
       "Arbol de Decision (criterion='gini', splitter='...                  0.951952   \n",
       "Arbol de Decision 6 predictoras (default)                           0.960961   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...                  0.948949   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...                  0.987988   \n",
       "Bosques                                                             0.975976   \n",
       "XGBoosting                                                          0.981982   \n",
       "ADA Boosting                                                        0.987988   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...                  0.975976   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...                  0.942943   \n",
       "ADA Boosting (n_estimators=7, random_state=0)                       0.987988   \n",
       "\n",
       "                                                    Precisi´on Negativa (PN)  \\\n",
       "K-vecinos todas variables                                           0.707641   \n",
       "K-vecinos 6 variables                                               0.983389   \n",
       "Arbol de Decision (default)                                         0.956811   \n",
       "Arbol de Decision (criterion='entropy',max_dept...                  0.940199   \n",
       "Arbol de Decision (criterion='gini', splitter='...                  0.843854   \n",
       "Arbol de Decision 6 predictoras (default)                           0.973422   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...                  0.940199   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...                  0.837209   \n",
       "Bosques                                                             0.986711   \n",
       "XGBoosting                                                          0.973422   \n",
       "ADA Boosting                                                        0.940199   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...                  0.930233   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...                  0.983389   \n",
       "ADA Boosting (n_estimators=7, random_state=0)                       0.926910   \n",
       "\n",
       "                                                    Falsos Positivos (FP)  \\\n",
       "K-vecinos todas variables                                        0.292359   \n",
       "K-vecinos 6 variables                                            0.016611   \n",
       "Arbol de Decision (default)                                      0.043189   \n",
       "Arbol de Decision (criterion='entropy',max_dept...               0.059801   \n",
       "Arbol de Decision (criterion='gini', splitter='...               0.156146   \n",
       "Arbol de Decision 6 predictoras (default)                        0.026578   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...               0.059801   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...               0.162791   \n",
       "Bosques                                                          0.013289   \n",
       "XGBoosting                                                       0.026578   \n",
       "ADA Boosting                                                     0.059801   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...               0.069767   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...               0.016611   \n",
       "ADA Boosting (n_estimators=7, random_state=0)                    0.073090   \n",
       "\n",
       "                                                    Falsos Negativos (FN)  \\\n",
       "K-vecinos todas variables                                        0.228228   \n",
       "K-vecinos 6 variables                                            0.024024   \n",
       "Arbol de Decision (default)                                      0.036036   \n",
       "Arbol de Decision (criterion='entropy',max_dept...               0.051051   \n",
       "Arbol de Decision (criterion='gini', splitter='...               0.048048   \n",
       "Arbol de Decision 6 predictoras (default)                        0.039039   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...               0.051051   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...               0.012012   \n",
       "Bosques                                                          0.024024   \n",
       "XGBoosting                                                       0.018018   \n",
       "ADA Boosting                                                     0.012012   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...               0.024024   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...               0.057057   \n",
       "ADA Boosting (n_estimators=7, random_state=0)                    0.012012   \n",
       "\n",
       "                                                    Asertividad Positiva (AP)  \\\n",
       "K-vecinos todas variables                                            0.744928   \n",
       "K-vecinos 6 variables                                                0.984848   \n",
       "Arbol de Decision (default)                                          0.961078   \n",
       "Arbol de Decision (criterion='entropy',max_dept...                   0.946108   \n",
       "Arbol de Decision (criterion='gini', splitter='...                   0.870879   \n",
       "Arbol de Decision 6 predictoras (default)                            0.975610   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...                   0.946108   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...                   0.870370   \n",
       "Bosques                                                              0.987842   \n",
       "XGBoosting                                                           0.976119   \n",
       "ADA Boosting                                                         0.948127   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...                   0.939306   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...                   0.984326   \n",
       "ADA Boosting (n_estimators=7, random_state=0)                        0.937322   \n",
       "\n",
       "                                                    Asertividad Negativa (AN)  \n",
       "K-vecinos todas variables                                            0.737024  \n",
       "K-vecinos 6 variables                                                0.973684  \n",
       "Arbol de Decision (default)                                          0.960000  \n",
       "Arbol de Decision (criterion='entropy',max_dept...                   0.943333  \n",
       "Arbol de Decision (criterion='gini', splitter='...                   0.940741  \n",
       "Arbol de Decision 6 predictoras (default)                            0.957516  \n",
       "Arbol de Decision 6 predictoras (criterion='ent...                   0.943333  \n",
       "Arbol de Decision 6 predictoras (criterion='gin...                   0.984375  \n",
       "Bosques                                                              0.973770  \n",
       "XGBoosting                                                           0.979933  \n",
       "ADA Boosting                                                         0.986063  \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...                   0.972222  \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...                   0.939683  \n",
       "ADA Boosting (n_estimators=7, random_state=0)                        0.985866  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.matrix([[0.7413249211356467, 0.25867507886435326, 0.7717717717717718, 0.707641196013289, 0.292358803986711, 0.2282282282282282, 0.744927536231884, 0.7370242214532872],\n",
    "               [0.9794952681388013, 0.02050473186119872, 0.975975975975976, 0.9833887043189369, 0.01661129568106312, 0.024024024024024038, 0.9848484848484849, 0.9736842105263158],\n",
    "              [0.9605678233438486, 0.039432176656151396, 0.963963963963964, 0.9568106312292359, 0.04318936877076407, 0.036036036036036, 0.9610778443113772, 0.96],\n",
    "              [0.944794952681388, 0.05520504731861198, 0.948948948948949, 0.9401993355481728, 0.05980066445182719, 0.05105105105105101, 0.9461077844311377, 0.9433333333333334],\n",
    "              [0.9006309148264984, 0.09936908517350163, 0.9519519519519519, 0.8438538205980066, 0.15614617940199338, 0.048048048048048075, 0.8708791208791209, 0.9407407407407408],\n",
    "              [0.9668769716088328, 0.03312302839116721, 0.960960960960961, 0.973421926910299, 0.02657807308970095, 0.03903903903903905, 0.975609756097561, 0.9575163398692811],\n",
    "              [0.944794952681388, 0.05520504731861198, 0.948948948948949, 0.9401993355481728, 0.05980066445182719, 0.05105105105105101, 0.9461077844311377, 0.9433333333333334],\n",
    "              [0.916403785488959, 0.08359621451104104, 0.987987987987988, 0.8372093023255814, 0.16279069767441856, 0.012012012012011963, 0.8703703703703703, 0.984375],\n",
    "              [0.9810725552050473, 0.018927444794952675, 0.975975975975976, 0.9867109634551495, 0.013289036544850474, 0.024024024024024038, 0.9878419452887538, 0.9737704918032787],\n",
    "              [0.9779179810725552, 0.02208201892744477, 0.9819819819819819, 0.973421926910299, 0.02657807308970095, 0.018018018018018056, 0.9761194029850746, 0.979933110367893],\n",
    "              [0.9652996845425867, 0.034700315457413256, 0.987987987987988, 0.9401993355481728, 0.05980066445182719, 0.012012012012011963, 0.9481268011527377, 0.9860627177700348],\n",
    "              [0.9542586750788643, 0.045741324921135695, 0.975975975975976, 0.9302325581395349, 0.06976744186046513, 0.024024024024024038, 0.9393063583815029, 0.9722222222222222],\n",
    "              [0.9621451104100947, 0.03785488958990535, 0.9429429429429429, 0.9833887043189369, 0.01661129568106312, 0.0570570570570571, 0.9843260188087775, 0.9396825396825397],\n",
    "              [0.9589905362776026, 0.04100946372239744, 0.987987987987988, 0.9269102990033222, 0.07308970099667778, 0.012012012012011963, 0.9373219373219374, 0.9858657243816255]])\n",
    "mi_df = pd.DataFrame(A)\n",
    "nombres_filas = [\"K-vecinos todas variables\",\"K-vecinos 6 variables\",\"Arbol de Decision (default)\",\"Arbol de Decision (criterion='entropy',max_depth=2)\",\"Arbol de Decision (criterion='gini', splitter='random', max_depth=3)\",\n",
    "                 \"Arbol de Decision 6 predictoras (default)\",\"Arbol de Decision 6 predictoras (criterion='entropy',max_depth=2)\",\"Arbol de Decision 6 predictoras (criterion='gini', splitter='random', max_depth=3)\", \n",
    "                 \"Bosques\", \"XGBoosting\", \"ADA Boosting\", \"Bosques (n_estimators=7, max_depth=2, random_state=0) \", \"XGBoosting(n_estimators=7, max_depth=2, random_state=0)\", \"ADA Boosting (n_estimators=7, random_state=0)\"]\n",
    "nombres_columnas = [\"Precisi´on Global\",\"Error Global\",\"Precisi´on Positiva (PP)\", \"Precisi´on Negativa (PN)\", \"Falsos Positivos (FP)\", \"Falsos Negativos (FN)\", \"Asertividad Positiva (AP)\", \"Asertividad Negativa (AN)\"]\n",
    "mi_df = pd.DataFrame(A, index = nombres_filas, columns = nombres_columnas )\n",
    "mi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de limitarse los parametros, en este caso las estimaciones a pesar de no mejorar, no sufren realmente una bajada considerable en su nivel de precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Repita los ejercicios 1-4, pero esta vez use 2 combinaciones diferentes de selecci´on de 6 variables predictoras. ¿Mejora la predicci´on?."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio se usa primero la combinacion de: meanfun, IQR, Q25, sd, sp.ent, centroid; ya que es la mejor combinacion de bosques, debido a que XGBoosting muestra una cantidad limitada y que combina vagamente los dos otros metodos, se toman las mejores 6 de ADA: maxdom, minfun, meanfun, sfm, IQR, sd.\n",
    "Para los parametros se emplearan los parametros n_estimators=700, max_depth=200, random_state=0 para darle mas margen a la funcion, y explorar este cambio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sd       Q25       IQR    sp.ent  centroid   meanfun\n",
      "0  0.064241  0.015071  0.075122  0.893369  0.059781  0.084279\n",
      "1  0.067310  0.019414  0.073252  0.892193  0.066009  0.107937\n",
      "2  0.083829  0.008701  0.123207  0.846389  0.077316  0.098706\n",
      "3  0.072111  0.096582  0.111374  0.963322  0.151228  0.088965\n",
      "4  0.079146  0.078720  0.127325  0.971955  0.135120  0.106398\n",
      "      genero\n",
      "0  Masculino\n",
      "1  Masculino\n",
      "2  Masculino\n",
      "3  Masculino\n",
      "4  Masculino\n"
     ]
    }
   ],
   "source": [
    "##Opcion 1\n",
    "X = datos.iloc[:,[1,3,5,8,11,12]] \n",
    "print(X.head())\n",
    "y = datos.iloc[:,20:21]\n",
    "print(y.head())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[297   4]\n",
      " [  8 325]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9810725552050473\n",
      "\n",
      "Error Global:\n",
      "0.018927444794952675\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.986711   0.975976\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.975975975975976\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9867109634551495\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.013289036544850474\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.024024024024024038\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9878419452887538\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9737704918032787\n"
     ]
    }
   ],
   "source": [
    "##Bosques\n",
    "instancia_bosque = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "instancia_bosque.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_bosque.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[289  12]\n",
      " [  8 325]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9684542586750788\n",
      "\n",
      "Error Global:\n",
      "0.03154574132492116\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.960133   0.975976\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.975975975975976\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9601328903654485\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.039867109634551534\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.024024024024024038\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9643916913946587\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9730639730639731\n"
     ]
    }
   ],
   "source": [
    "###XGBoosting\n",
    "instancia_potenciacion = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[285  16]\n",
      " [ 11 322]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9574132492113565\n",
      "\n",
      "Error Global:\n",
      "0.04258675078864349\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.946844   0.966967\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9669669669669669\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.946843853820598\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.05315614617940201\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.033033033033033066\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9526627218934911\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9628378378378378\n"
     ]
    }
   ],
   "source": [
    "###ADA Boosting\n",
    "instancia_potenciacion = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[296   5]\n",
      " [  6 327]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9826498422712934\n",
      "\n",
      "Error Global:\n",
      "0.017350157728706628\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.983389   0.981982\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9819819819819819\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9833887043189369\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.01661129568106312\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.018018018018018056\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9849397590361446\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9801324503311258\n"
     ]
    }
   ],
   "source": [
    "###Diferentes parametros\n",
    "##Bosques\n",
    "instancia_bosque = RandomForestClassifier(n_estimators=700, max_depth=200, random_state=0)\n",
    "instancia_bosque.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_bosque.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[289  12]\n",
      " [ 10 323]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9652996845425867\n",
      "\n",
      "Error Global:\n",
      "0.034700315457413256\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.960133    0.96997\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.96996996996997\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9601328903654485\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.039867109634551534\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.03003003003003002\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9641791044776119\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9665551839464883\n"
     ]
    }
   ],
   "source": [
    "###XGBoosting\n",
    "instancia_potenciacion = GradientBoostingClassifier(n_estimators=700, max_depth=200, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[284  17]\n",
      " [  6 327]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9637223974763407\n",
      "\n",
      "Error Global:\n",
      "0.0362776025236593\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.943522   0.981982\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9819819819819819\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9435215946843853\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.056478405315614655\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.018018018018018056\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9505813953488372\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9793103448275862\n"
     ]
    }
   ],
   "source": [
    "###ADA Boosting\n",
    "instancia_potenciacion = AdaBoostClassifier(n_estimators=700, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sd       IQR       sfm   meanfun    minfun    maxdom\n",
      "0  0.064241  0.075122  0.491918  0.084279  0.015702  0.007812\n",
      "1  0.067310  0.073252  0.513724  0.107937  0.015826  0.054688\n",
      "2  0.083829  0.123207  0.478905  0.098706  0.015656  0.015625\n",
      "3  0.072111  0.111374  0.727232  0.088965  0.017798  0.562500\n",
      "4  0.079146  0.127325  0.783568  0.106398  0.016931  5.484375\n",
      "      genero\n",
      "0  Masculino\n",
      "1  Masculino\n",
      "2  Masculino\n",
      "3  Masculino\n",
      "4  Masculino\n"
     ]
    }
   ],
   "source": [
    "##Opcion 2\n",
    "X = datos.iloc[:,[1,5,9,12,13,17]] \n",
    "print(X.head())\n",
    "y = datos.iloc[:,20:21]\n",
    "print(y.head())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[294   7]\n",
      " [  7 326]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9779179810725552\n",
      "\n",
      "Error Global:\n",
      "0.02208201892744477\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.976744   0.978979\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.978978978978979\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9767441860465116\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.023255813953488413\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.02102102102102099\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.978978978978979\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9767441860465116\n"
     ]
    }
   ],
   "source": [
    "##Bosques\n",
    "instancia_bosque = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "instancia_bosque.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_bosque.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[293   8]\n",
      " [  9 324]]\n",
      "\n",
      "Precisión Global:\n",
      "0.973186119873817\n",
      "\n",
      "Error Global:\n",
      "0.02681388012618302\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.973422   0.972973\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.972972972972973\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.973421926910299\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.02657807308970095\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.027027027027026973\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9759036144578314\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9701986754966887\n"
     ]
    }
   ],
   "source": [
    "###XGBoosting\n",
    "instancia_potenciacion = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[283  18]\n",
      " [  4 329]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9652996845425867\n",
      "\n",
      "Error Global:\n",
      "0.034700315457413256\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.940199   0.987988\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.987987987987988\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9401993355481728\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.05980066445182719\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.012012012012011963\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9481268011527377\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9860627177700348\n"
     ]
    }
   ],
   "source": [
    "###ADA Boosting\n",
    "instancia_potenciacion = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[295   6]\n",
      " [  8 325]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9779179810725552\n",
      "\n",
      "Error Global:\n",
      "0.02208201892744477\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.980066   0.975976\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.975975975975976\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9800664451827242\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.019933554817275767\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.024024024024024038\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9818731117824774\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9735973597359736\n"
     ]
    }
   ],
   "source": [
    "###Diferentes parametros\n",
    "##Bosques\n",
    "instancia_bosque = RandomForestClassifier(n_estimators=700, max_depth=200, random_state=0)\n",
    "instancia_bosque.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_bosque.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[291  10]\n",
      " [ 12 321]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9652996845425867\n",
      "\n",
      "Error Global:\n",
      "0.034700315457413256\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.966777   0.963964\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.963963963963964\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9667774086378738\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.03322259136212624\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.036036036036036\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9697885196374623\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9603960396039604\n"
     ]
    }
   ],
   "source": [
    "###XGBoosting\n",
    "instancia_potenciacion = GradientBoostingClassifier(n_estimators=700, max_depth=200, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[291  10]\n",
      " [  8 325]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9716088328075709\n",
      "\n",
      "Error Global:\n",
      "0.028391167192429068\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.966777   0.975976\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.975975975975976\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9667774086378738\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.03322259136212624\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.024024024024024038\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9701492537313433\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9732441471571907\n"
     ]
    }
   ],
   "source": [
    "###ADA Boosting\n",
    "instancia_potenciacion = AdaBoostClassifier(n_estimators=700, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precisi´on Global</th>\n",
       "      <th>Error Global</th>\n",
       "      <th>Precisi´on Positiva (PP)</th>\n",
       "      <th>Precisi´on Negativa (PN)</th>\n",
       "      <th>Falsos Positivos (FP)</th>\n",
       "      <th>Falsos Negativos (FN)</th>\n",
       "      <th>Asertividad Positiva (AP)</th>\n",
       "      <th>Asertividad Negativa (AN)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K-vecinos todas variables</th>\n",
       "      <td>0.741325</td>\n",
       "      <td>0.258675</td>\n",
       "      <td>0.771772</td>\n",
       "      <td>0.707641</td>\n",
       "      <td>0.292359</td>\n",
       "      <td>0.228228</td>\n",
       "      <td>0.744928</td>\n",
       "      <td>0.737024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-vecinos 6 variables</th>\n",
       "      <td>0.979495</td>\n",
       "      <td>0.020505</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.983389</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision (default)</th>\n",
       "      <td>0.960568</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>0.956811</td>\n",
       "      <td>0.043189</td>\n",
       "      <td>0.036036</td>\n",
       "      <td>0.961078</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision (criterion='entropy',max_depth=2)</th>\n",
       "      <td>0.944795</td>\n",
       "      <td>0.055205</td>\n",
       "      <td>0.948949</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.051051</td>\n",
       "      <td>0.946108</td>\n",
       "      <td>0.943333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision (criterion='gini', splitter='random', max_depth=3)</th>\n",
       "      <td>0.900631</td>\n",
       "      <td>0.099369</td>\n",
       "      <td>0.951952</td>\n",
       "      <td>0.843854</td>\n",
       "      <td>0.156146</td>\n",
       "      <td>0.048048</td>\n",
       "      <td>0.870879</td>\n",
       "      <td>0.940741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision 6 predictoras (default)</th>\n",
       "      <td>0.966877</td>\n",
       "      <td>0.033123</td>\n",
       "      <td>0.960961</td>\n",
       "      <td>0.973422</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.039039</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.957516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision 6 predictoras (criterion='entropy',max_depth=2)</th>\n",
       "      <td>0.944795</td>\n",
       "      <td>0.055205</td>\n",
       "      <td>0.948949</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.051051</td>\n",
       "      <td>0.946108</td>\n",
       "      <td>0.943333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision 6 predictoras (criterion='gini', splitter='random', max_depth=3)</th>\n",
       "      <td>0.916404</td>\n",
       "      <td>0.083596</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosques</th>\n",
       "      <td>0.981073</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.986711</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.987842</td>\n",
       "      <td>0.973770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting</th>\n",
       "      <td>0.977918</td>\n",
       "      <td>0.022082</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>0.973422</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.976119</td>\n",
       "      <td>0.979933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA Boosting</th>\n",
       "      <td>0.965300</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.948127</td>\n",
       "      <td>0.986063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosques (n_estimators=7, max_depth=2, random_state=0)</th>\n",
       "      <td>0.954259</td>\n",
       "      <td>0.045741</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.939306</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting(n_estimators=7, max_depth=2, random_state=0)</th>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.037855</td>\n",
       "      <td>0.942943</td>\n",
       "      <td>0.983389</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.057057</td>\n",
       "      <td>0.984326</td>\n",
       "      <td>0.939683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA Boosting (n_estimators=7, random_state=0)</th>\n",
       "      <td>0.958991</td>\n",
       "      <td>0.041009</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.926910</td>\n",
       "      <td>0.073090</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.937322</td>\n",
       "      <td>0.985866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosques 6 predictoras (opcion 1)</th>\n",
       "      <td>0.981073</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.986711</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.987842</td>\n",
       "      <td>0.973770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting 6 predictoras (opcion 1)</th>\n",
       "      <td>0.968454</td>\n",
       "      <td>0.031546</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.960133</td>\n",
       "      <td>0.039867</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.973064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA Boosting 6 predictoras(opcion 1)</th>\n",
       "      <td>0.957413</td>\n",
       "      <td>0.042587</td>\n",
       "      <td>0.966967</td>\n",
       "      <td>0.946844</td>\n",
       "      <td>0.053156</td>\n",
       "      <td>0.033033</td>\n",
       "      <td>0.952663</td>\n",
       "      <td>0.962838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosques 6 predictoras (opcion 1)(n_estimators=700, max_depth=200, random_state=0)</th>\n",
       "      <td>0.982650</td>\n",
       "      <td>0.017350</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>0.983389</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.980132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting 6 predictoras (opcion 1)(n_estimators=700, max_depth=200, random_state=0)</th>\n",
       "      <td>0.965300</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.969970</td>\n",
       "      <td>0.960133</td>\n",
       "      <td>0.039867</td>\n",
       "      <td>0.030030</td>\n",
       "      <td>0.964179</td>\n",
       "      <td>0.966555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA Boosting 6 predictoras(opcion 1)(n_estimators=700, random_state=0)</th>\n",
       "      <td>0.963722</td>\n",
       "      <td>0.036278</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>0.943522</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.950581</td>\n",
       "      <td>0.979310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosques 6 predictoras (opcion 2)</th>\n",
       "      <td>0.977918</td>\n",
       "      <td>0.022082</td>\n",
       "      <td>0.978979</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.021021</td>\n",
       "      <td>0.978979</td>\n",
       "      <td>0.976744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting 6 predictoras (opcion 2)</th>\n",
       "      <td>0.973186</td>\n",
       "      <td>0.026814</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.973422</td>\n",
       "      <td>0.026578</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.970199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA Boosting 6 predictoras(opcion 2)</th>\n",
       "      <td>0.965300</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.940199</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.948127</td>\n",
       "      <td>0.986063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosques 6 predictoras (opcion 2)(n_estimators=700, max_depth=200, random_state=0)</th>\n",
       "      <td>0.977918</td>\n",
       "      <td>0.022082</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.980066</td>\n",
       "      <td>0.019934</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.981873</td>\n",
       "      <td>0.973597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting 6 predictoras (opcion 2)(n_estimators=700, max_depth=200, random_state=0)</th>\n",
       "      <td>0.965300</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>0.966777</td>\n",
       "      <td>0.033223</td>\n",
       "      <td>0.036036</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>0.960396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA Boosting 6 predictoras(opcion 2)(n_estimators=700, random_state=0)</th>\n",
       "      <td>0.971609</td>\n",
       "      <td>0.028391</td>\n",
       "      <td>0.975976</td>\n",
       "      <td>0.966777</td>\n",
       "      <td>0.033223</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.970149</td>\n",
       "      <td>0.973244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Precisi´on Global  \\\n",
       "K-vecinos todas variables                                    0.741325   \n",
       "K-vecinos 6 variables                                        0.979495   \n",
       "Arbol de Decision (default)                                  0.960568   \n",
       "Arbol de Decision (criterion='entropy',max_dept...           0.944795   \n",
       "Arbol de Decision (criterion='gini', splitter='...           0.900631   \n",
       "Arbol de Decision 6 predictoras (default)                    0.966877   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...           0.944795   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...           0.916404   \n",
       "Bosques                                                      0.981073   \n",
       "XGBoosting                                                   0.977918   \n",
       "ADA Boosting                                                 0.965300   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...           0.954259   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...           0.962145   \n",
       "ADA Boosting (n_estimators=7, random_state=0)                0.958991   \n",
       "Bosques 6 predictoras (opcion 1)                             0.981073   \n",
       "XGBoosting 6 predictoras (opcion 1)                          0.968454   \n",
       "ADA Boosting 6 predictoras(opcion 1)                         0.957413   \n",
       "Bosques 6 predictoras (opcion 1)(n_estimators=7...           0.982650   \n",
       "XGBoosting 6 predictoras (opcion 1)(n_estimator...           0.965300   \n",
       "ADA Boosting 6 predictoras(opcion 1)(n_estimato...           0.963722   \n",
       "Bosques 6 predictoras (opcion 2)                             0.977918   \n",
       "XGBoosting 6 predictoras (opcion 2)                          0.973186   \n",
       "ADA Boosting 6 predictoras(opcion 2)                         0.965300   \n",
       "Bosques 6 predictoras (opcion 2)(n_estimators=7...           0.977918   \n",
       "XGBoosting 6 predictoras (opcion 2)(n_estimator...           0.965300   \n",
       "ADA Boosting 6 predictoras(opcion 2)(n_estimato...           0.971609   \n",
       "\n",
       "                                                    Error Global  \\\n",
       "K-vecinos todas variables                               0.258675   \n",
       "K-vecinos 6 variables                                   0.020505   \n",
       "Arbol de Decision (default)                             0.039432   \n",
       "Arbol de Decision (criterion='entropy',max_dept...      0.055205   \n",
       "Arbol de Decision (criterion='gini', splitter='...      0.099369   \n",
       "Arbol de Decision 6 predictoras (default)               0.033123   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...      0.055205   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...      0.083596   \n",
       "Bosques                                                 0.018927   \n",
       "XGBoosting                                              0.022082   \n",
       "ADA Boosting                                            0.034700   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...      0.045741   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...      0.037855   \n",
       "ADA Boosting (n_estimators=7, random_state=0)           0.041009   \n",
       "Bosques 6 predictoras (opcion 1)                        0.018927   \n",
       "XGBoosting 6 predictoras (opcion 1)                     0.031546   \n",
       "ADA Boosting 6 predictoras(opcion 1)                    0.042587   \n",
       "Bosques 6 predictoras (opcion 1)(n_estimators=7...      0.017350   \n",
       "XGBoosting 6 predictoras (opcion 1)(n_estimator...      0.034700   \n",
       "ADA Boosting 6 predictoras(opcion 1)(n_estimato...      0.036278   \n",
       "Bosques 6 predictoras (opcion 2)                        0.022082   \n",
       "XGBoosting 6 predictoras (opcion 2)                     0.026814   \n",
       "ADA Boosting 6 predictoras(opcion 2)                    0.034700   \n",
       "Bosques 6 predictoras (opcion 2)(n_estimators=7...      0.022082   \n",
       "XGBoosting 6 predictoras (opcion 2)(n_estimator...      0.034700   \n",
       "ADA Boosting 6 predictoras(opcion 2)(n_estimato...      0.028391   \n",
       "\n",
       "                                                    Precisi´on Positiva (PP)  \\\n",
       "K-vecinos todas variables                                           0.771772   \n",
       "K-vecinos 6 variables                                               0.975976   \n",
       "Arbol de Decision (default)                                         0.963964   \n",
       "Arbol de Decision (criterion='entropy',max_dept...                  0.948949   \n",
       "Arbol de Decision (criterion='gini', splitter='...                  0.951952   \n",
       "Arbol de Decision 6 predictoras (default)                           0.960961   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...                  0.948949   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...                  0.987988   \n",
       "Bosques                                                             0.975976   \n",
       "XGBoosting                                                          0.981982   \n",
       "ADA Boosting                                                        0.987988   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...                  0.975976   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...                  0.942943   \n",
       "ADA Boosting (n_estimators=7, random_state=0)                       0.987988   \n",
       "Bosques 6 predictoras (opcion 1)                                    0.975976   \n",
       "XGBoosting 6 predictoras (opcion 1)                                 0.975976   \n",
       "ADA Boosting 6 predictoras(opcion 1)                                0.966967   \n",
       "Bosques 6 predictoras (opcion 1)(n_estimators=7...                  0.981982   \n",
       "XGBoosting 6 predictoras (opcion 1)(n_estimator...                  0.969970   \n",
       "ADA Boosting 6 predictoras(opcion 1)(n_estimato...                  0.981982   \n",
       "Bosques 6 predictoras (opcion 2)                                    0.978979   \n",
       "XGBoosting 6 predictoras (opcion 2)                                 0.972973   \n",
       "ADA Boosting 6 predictoras(opcion 2)                                0.987988   \n",
       "Bosques 6 predictoras (opcion 2)(n_estimators=7...                  0.975976   \n",
       "XGBoosting 6 predictoras (opcion 2)(n_estimator...                  0.963964   \n",
       "ADA Boosting 6 predictoras(opcion 2)(n_estimato...                  0.975976   \n",
       "\n",
       "                                                    Precisi´on Negativa (PN)  \\\n",
       "K-vecinos todas variables                                           0.707641   \n",
       "K-vecinos 6 variables                                               0.983389   \n",
       "Arbol de Decision (default)                                         0.956811   \n",
       "Arbol de Decision (criterion='entropy',max_dept...                  0.940199   \n",
       "Arbol de Decision (criterion='gini', splitter='...                  0.843854   \n",
       "Arbol de Decision 6 predictoras (default)                           0.973422   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...                  0.940199   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...                  0.837209   \n",
       "Bosques                                                             0.986711   \n",
       "XGBoosting                                                          0.973422   \n",
       "ADA Boosting                                                        0.940199   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...                  0.930233   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...                  0.983389   \n",
       "ADA Boosting (n_estimators=7, random_state=0)                       0.926910   \n",
       "Bosques 6 predictoras (opcion 1)                                    0.986711   \n",
       "XGBoosting 6 predictoras (opcion 1)                                 0.960133   \n",
       "ADA Boosting 6 predictoras(opcion 1)                                0.946844   \n",
       "Bosques 6 predictoras (opcion 1)(n_estimators=7...                  0.983389   \n",
       "XGBoosting 6 predictoras (opcion 1)(n_estimator...                  0.960133   \n",
       "ADA Boosting 6 predictoras(opcion 1)(n_estimato...                  0.943522   \n",
       "Bosques 6 predictoras (opcion 2)                                    0.976744   \n",
       "XGBoosting 6 predictoras (opcion 2)                                 0.973422   \n",
       "ADA Boosting 6 predictoras(opcion 2)                                0.940199   \n",
       "Bosques 6 predictoras (opcion 2)(n_estimators=7...                  0.980066   \n",
       "XGBoosting 6 predictoras (opcion 2)(n_estimator...                  0.966777   \n",
       "ADA Boosting 6 predictoras(opcion 2)(n_estimato...                  0.966777   \n",
       "\n",
       "                                                    Falsos Positivos (FP)  \\\n",
       "K-vecinos todas variables                                        0.292359   \n",
       "K-vecinos 6 variables                                            0.016611   \n",
       "Arbol de Decision (default)                                      0.043189   \n",
       "Arbol de Decision (criterion='entropy',max_dept...               0.059801   \n",
       "Arbol de Decision (criterion='gini', splitter='...               0.156146   \n",
       "Arbol de Decision 6 predictoras (default)                        0.026578   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...               0.059801   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...               0.162791   \n",
       "Bosques                                                          0.013289   \n",
       "XGBoosting                                                       0.026578   \n",
       "ADA Boosting                                                     0.059801   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...               0.069767   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...               0.016611   \n",
       "ADA Boosting (n_estimators=7, random_state=0)                    0.073090   \n",
       "Bosques 6 predictoras (opcion 1)                                 0.013289   \n",
       "XGBoosting 6 predictoras (opcion 1)                              0.039867   \n",
       "ADA Boosting 6 predictoras(opcion 1)                             0.053156   \n",
       "Bosques 6 predictoras (opcion 1)(n_estimators=7...               0.016611   \n",
       "XGBoosting 6 predictoras (opcion 1)(n_estimator...               0.039867   \n",
       "ADA Boosting 6 predictoras(opcion 1)(n_estimato...               0.056478   \n",
       "Bosques 6 predictoras (opcion 2)                                 0.023256   \n",
       "XGBoosting 6 predictoras (opcion 2)                              0.026578   \n",
       "ADA Boosting 6 predictoras(opcion 2)                             0.059801   \n",
       "Bosques 6 predictoras (opcion 2)(n_estimators=7...               0.019934   \n",
       "XGBoosting 6 predictoras (opcion 2)(n_estimator...               0.033223   \n",
       "ADA Boosting 6 predictoras(opcion 2)(n_estimato...               0.033223   \n",
       "\n",
       "                                                    Falsos Negativos (FN)  \\\n",
       "K-vecinos todas variables                                        0.228228   \n",
       "K-vecinos 6 variables                                            0.024024   \n",
       "Arbol de Decision (default)                                      0.036036   \n",
       "Arbol de Decision (criterion='entropy',max_dept...               0.051051   \n",
       "Arbol de Decision (criterion='gini', splitter='...               0.048048   \n",
       "Arbol de Decision 6 predictoras (default)                        0.039039   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...               0.051051   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...               0.012012   \n",
       "Bosques                                                          0.024024   \n",
       "XGBoosting                                                       0.018018   \n",
       "ADA Boosting                                                     0.012012   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...               0.024024   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...               0.057057   \n",
       "ADA Boosting (n_estimators=7, random_state=0)                    0.012012   \n",
       "Bosques 6 predictoras (opcion 1)                                 0.024024   \n",
       "XGBoosting 6 predictoras (opcion 1)                              0.024024   \n",
       "ADA Boosting 6 predictoras(opcion 1)                             0.033033   \n",
       "Bosques 6 predictoras (opcion 1)(n_estimators=7...               0.018018   \n",
       "XGBoosting 6 predictoras (opcion 1)(n_estimator...               0.030030   \n",
       "ADA Boosting 6 predictoras(opcion 1)(n_estimato...               0.018018   \n",
       "Bosques 6 predictoras (opcion 2)                                 0.021021   \n",
       "XGBoosting 6 predictoras (opcion 2)                              0.027027   \n",
       "ADA Boosting 6 predictoras(opcion 2)                             0.012012   \n",
       "Bosques 6 predictoras (opcion 2)(n_estimators=7...               0.024024   \n",
       "XGBoosting 6 predictoras (opcion 2)(n_estimator...               0.036036   \n",
       "ADA Boosting 6 predictoras(opcion 2)(n_estimato...               0.024024   \n",
       "\n",
       "                                                    Asertividad Positiva (AP)  \\\n",
       "K-vecinos todas variables                                            0.744928   \n",
       "K-vecinos 6 variables                                                0.984848   \n",
       "Arbol de Decision (default)                                          0.961078   \n",
       "Arbol de Decision (criterion='entropy',max_dept...                   0.946108   \n",
       "Arbol de Decision (criterion='gini', splitter='...                   0.870879   \n",
       "Arbol de Decision 6 predictoras (default)                            0.975610   \n",
       "Arbol de Decision 6 predictoras (criterion='ent...                   0.946108   \n",
       "Arbol de Decision 6 predictoras (criterion='gin...                   0.870370   \n",
       "Bosques                                                              0.987842   \n",
       "XGBoosting                                                           0.976119   \n",
       "ADA Boosting                                                         0.948127   \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...                   0.939306   \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...                   0.984326   \n",
       "ADA Boosting (n_estimators=7, random_state=0)                        0.937322   \n",
       "Bosques 6 predictoras (opcion 1)                                     0.987842   \n",
       "XGBoosting 6 predictoras (opcion 1)                                  0.964392   \n",
       "ADA Boosting 6 predictoras(opcion 1)                                 0.952663   \n",
       "Bosques 6 predictoras (opcion 1)(n_estimators=7...                   0.984940   \n",
       "XGBoosting 6 predictoras (opcion 1)(n_estimator...                   0.964179   \n",
       "ADA Boosting 6 predictoras(opcion 1)(n_estimato...                   0.950581   \n",
       "Bosques 6 predictoras (opcion 2)                                     0.978979   \n",
       "XGBoosting 6 predictoras (opcion 2)                                  0.975904   \n",
       "ADA Boosting 6 predictoras(opcion 2)                                 0.948127   \n",
       "Bosques 6 predictoras (opcion 2)(n_estimators=7...                   0.981873   \n",
       "XGBoosting 6 predictoras (opcion 2)(n_estimator...                   0.969789   \n",
       "ADA Boosting 6 predictoras(opcion 2)(n_estimato...                   0.970149   \n",
       "\n",
       "                                                    Asertividad Negativa (AN)  \n",
       "K-vecinos todas variables                                            0.737024  \n",
       "K-vecinos 6 variables                                                0.973684  \n",
       "Arbol de Decision (default)                                          0.960000  \n",
       "Arbol de Decision (criterion='entropy',max_dept...                   0.943333  \n",
       "Arbol de Decision (criterion='gini', splitter='...                   0.940741  \n",
       "Arbol de Decision 6 predictoras (default)                            0.957516  \n",
       "Arbol de Decision 6 predictoras (criterion='ent...                   0.943333  \n",
       "Arbol de Decision 6 predictoras (criterion='gin...                   0.984375  \n",
       "Bosques                                                              0.973770  \n",
       "XGBoosting                                                           0.979933  \n",
       "ADA Boosting                                                         0.986063  \n",
       "Bosques (n_estimators=7, max_depth=2, random_st...                   0.972222  \n",
       "XGBoosting(n_estimators=7, max_depth=2, random_...                   0.939683  \n",
       "ADA Boosting (n_estimators=7, random_state=0)                        0.985866  \n",
       "Bosques 6 predictoras (opcion 1)                                     0.973770  \n",
       "XGBoosting 6 predictoras (opcion 1)                                  0.973064  \n",
       "ADA Boosting 6 predictoras(opcion 1)                                 0.962838  \n",
       "Bosques 6 predictoras (opcion 1)(n_estimators=7...                   0.980132  \n",
       "XGBoosting 6 predictoras (opcion 1)(n_estimator...                   0.966555  \n",
       "ADA Boosting 6 predictoras(opcion 1)(n_estimato...                   0.979310  \n",
       "Bosques 6 predictoras (opcion 2)                                     0.976744  \n",
       "XGBoosting 6 predictoras (opcion 2)                                  0.970199  \n",
       "ADA Boosting 6 predictoras(opcion 2)                                 0.986063  \n",
       "Bosques 6 predictoras (opcion 2)(n_estimators=7...                   0.973597  \n",
       "XGBoosting 6 predictoras (opcion 2)(n_estimator...                   0.960396  \n",
       "ADA Boosting 6 predictoras(opcion 2)(n_estimato...                   0.973244  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.matrix([[0.7413249211356467, 0.25867507886435326, 0.7717717717717718, 0.707641196013289, 0.292358803986711, 0.2282282282282282, 0.744927536231884, 0.7370242214532872],\n",
    "               [0.9794952681388013, 0.02050473186119872, 0.975975975975976, 0.9833887043189369, 0.01661129568106312, 0.024024024024024038, 0.9848484848484849, 0.9736842105263158],\n",
    "              [0.9605678233438486, 0.039432176656151396, 0.963963963963964, 0.9568106312292359, 0.04318936877076407, 0.036036036036036, 0.9610778443113772, 0.96],\n",
    "              [0.944794952681388, 0.05520504731861198, 0.948948948948949, 0.9401993355481728, 0.05980066445182719, 0.05105105105105101, 0.9461077844311377, 0.9433333333333334],\n",
    "              [0.9006309148264984, 0.09936908517350163, 0.9519519519519519, 0.8438538205980066, 0.15614617940199338, 0.048048048048048075, 0.8708791208791209, 0.9407407407407408],\n",
    "              [0.9668769716088328, 0.03312302839116721, 0.960960960960961, 0.973421926910299, 0.02657807308970095, 0.03903903903903905, 0.975609756097561, 0.9575163398692811],\n",
    "              [0.944794952681388, 0.05520504731861198, 0.948948948948949, 0.9401993355481728, 0.05980066445182719, 0.05105105105105101, 0.9461077844311377, 0.9433333333333334],\n",
    "              [0.916403785488959, 0.08359621451104104, 0.987987987987988, 0.8372093023255814, 0.16279069767441856, 0.012012012012011963, 0.8703703703703703, 0.984375],\n",
    "              [0.9810725552050473, 0.018927444794952675, 0.975975975975976, 0.9867109634551495, 0.013289036544850474, 0.024024024024024038, 0.9878419452887538, 0.9737704918032787],\n",
    "              [0.9779179810725552, 0.02208201892744477, 0.9819819819819819, 0.973421926910299, 0.02657807308970095, 0.018018018018018056, 0.9761194029850746, 0.979933110367893],\n",
    "              [0.9652996845425867, 0.034700315457413256, 0.987987987987988, 0.9401993355481728, 0.05980066445182719, 0.012012012012011963, 0.9481268011527377, 0.9860627177700348],\n",
    "              [0.9542586750788643, 0.045741324921135695, 0.975975975975976, 0.9302325581395349, 0.06976744186046513, 0.024024024024024038, 0.9393063583815029, 0.9722222222222222],\n",
    "              [0.9621451104100947, 0.03785488958990535, 0.9429429429429429, 0.9833887043189369, 0.01661129568106312, 0.0570570570570571, 0.9843260188087775, 0.9396825396825397],\n",
    "              [0.9589905362776026, 0.04100946372239744, 0.987987987987988, 0.9269102990033222, 0.07308970099667778, 0.012012012012011963, 0.9373219373219374, 0.9858657243816255],\n",
    "              [0.9810725552050473, 0.018927444794952675, 0.975975975975976, 0.9867109634551495, 0.013289036544850474, 0.024024024024024038, 0.9878419452887538, 0.9737704918032787],\n",
    "              [0.9684542586750788, 0.03154574132492116, 0.975975975975976, 0.9601328903654485, 0.039867109634551534, 0.024024024024024038, 0.9643916913946587, 0.9730639730639731],\n",
    "              [0.9574132492113565, 0.04258675078864349, 0.9669669669669669, 0.946843853820598, 0.05315614617940201, 0.033033033033033066, 0.9526627218934911, 0.9628378378378378],\n",
    "              [0.9826498422712934, 0.017350157728706628, 0.9819819819819819, 0.9833887043189369, 0.01661129568106312, 0.018018018018018056, 0.9849397590361446, 0.9801324503311258],\n",
    "              [0.9652996845425867, 0.034700315457413256, 0.96996996996997, 0.9601328903654485, 0.039867109634551534, 0.03003003003003002, 0.9641791044776119, 0.9665551839464883],\n",
    "              [0.9637223974763407, 0.0362776025236593, 0.9819819819819819, 0.9435215946843853, 0.056478405315614655, 0.018018018018018056, 0.9505813953488372, 0.9793103448275862],\n",
    "              [0.9779179810725552, 0.02208201892744477, 0.978978978978979, 0.9767441860465116, 0.023255813953488413, 0.02102102102102099, 0.978978978978979, 0.9767441860465116],\n",
    "              [0.973186119873817, 0.02681388012618302, 0.972972972972973, 0.973421926910299, 0.02657807308970095, 0.027027027027026973, 0.9759036144578314, 0.9701986754966887],\n",
    "              [0.9652996845425867, 0.034700315457413256, 0.987987987987988, 0.9401993355481728, 0.05980066445182719, 0.012012012012011963, 0.9481268011527377, 0.9860627177700348],\n",
    "              [0.9779179810725552, 0.02208201892744477, 0.975975975975976, 0.9800664451827242, 0.019933554817275767, 0.024024024024024038, 0.9818731117824774, 0.9735973597359736],\n",
    "              [0.9652996845425867, 0.034700315457413256, 0.963963963963964, 0.9667774086378738, 0.03322259136212624, 0.036036036036036, 0.9697885196374623, 0.9603960396039604],\n",
    "              [0.9716088328075709, 0.028391167192429068, 0.975975975975976, 0.9667774086378738, 0.03322259136212624, 0.024024024024024038, 0.9701492537313433, 0.9732441471571907]])\n",
    "mi_df = pd.DataFrame(A)\n",
    "nombres_filas = [\"K-vecinos todas variables\",\"K-vecinos 6 variables\",\"Arbol de Decision (default)\",\"Arbol de Decision (criterion='entropy',max_depth=2)\",\"Arbol de Decision (criterion='gini', splitter='random', max_depth=3)\",\n",
    "                 \"Arbol de Decision 6 predictoras (default)\",\"Arbol de Decision 6 predictoras (criterion='entropy',max_depth=2)\",\"Arbol de Decision 6 predictoras (criterion='gini', splitter='random', max_depth=3)\", \n",
    "                 \"Bosques\", \"XGBoosting\", \"ADA Boosting\", \"Bosques (n_estimators=7, max_depth=2, random_state=0) \", \"XGBoosting(n_estimators=7, max_depth=2, random_state=0)\", \"ADA Boosting (n_estimators=7, random_state=0)\",\n",
    "                 \"Bosques 6 predictoras (opcion 1)\", \"XGBoosting 6 predictoras (opcion 1)\", \"ADA Boosting 6 predictoras(opcion 1)\",\n",
    "                 \"Bosques 6 predictoras (opcion 1)(n_estimators=700, max_depth=200, random_state=0)\", \"XGBoosting 6 predictoras (opcion 1)(n_estimators=700, max_depth=200, random_state=0)\", \"ADA Boosting 6 predictoras(opcion 1)(n_estimators=700, random_state=0)\",\n",
    "                 \"Bosques 6 predictoras (opcion 2)\", \"XGBoosting 6 predictoras (opcion 2)\", \"ADA Boosting 6 predictoras(opcion 2)\",\n",
    "                 \"Bosques 6 predictoras (opcion 2)(n_estimators=700, max_depth=200, random_state=0)\", \"XGBoosting 6 predictoras (opcion 2)(n_estimators=700, max_depth=200, random_state=0)\", \"ADA Boosting 6 predictoras(opcion 2)(n_estimators=700, random_state=0)\"]\n",
    "nombres_columnas = [\"Precisi´on Global\",\"Error Global\",\"Precisi´on Positiva (PP)\", \"Precisi´on Negativa (PN)\", \"Falsos Positivos (FP)\", \"Falsos Negativos (FN)\", \"Asertividad Positiva (AP)\", \"Asertividad Negativa (AN)\"]\n",
    "mi_df = pd.DataFrame(A, index = nombres_filas, columns = nombres_columnas )\n",
    "mi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estos datos se denota que todos los metodos en general presentan buenos resultados. Los resultados mas precisos son los de bosques aleatorios, de hecho, el modelo de 6 variables predictoras Bosques 6 predictoras (opcion 1)(n_estimators=700, max_depth=200, random_state=0), donde las variables son: meanfun, IQR, Q25, sd, sp.ent, centroid. Tiene la precision global mas alta de 0.982650, es decir, logra identificar mejor los casos la PP y PN confirman esto, ademas los datos confundidas FP y FN son menores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio 2: [30 puntos] Esta pregunta utiliza los datos (tumores.csv). Se trata de un conjunto de datos de caracter´ısticas del tumor cerebral que incluye cinco variables de primer orden y ocho de textura y cuatro par´ametros de evaluaci´on de la calidad con el nivel objetivo. La variables son: Media, Varianza, Desviaci´on est´andar, Asimetr´ıa, Kurtosis, Contraste, Energ´ıa, ASM (segundo momento angular), Entrop´ıa, Homogeneidad, Disimilitud, Correlaci´on, Grosor, PSNR (Pico de la relaci´on se˜nal-ruido), SSIM (´Indice de Similitud Estructurada), MSE (Mean Square Error), DC (Coeficiente de Dados) y la variable a predecir tipo (1 = Tumor, 0 = No-Tumor).\n",
    "Realice lo siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use Bosques Aleatorios, ADABoosting y XGBoosting en Python para generar un modelo predictivo para la tabla tumores.csv usando el 70 % de los datos para la tabla aprendizaje y un 30 % para la tabla testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rzamoram\\Documents\\Machine Learning\\Métodos Supervisados con Python\\Clase 01\n",
      "(1275, 18)\n",
      "   imagen      media     varianza  desviacion.estandar  entropia  asimetria  \\\n",
      "0  Image1  23.448517  2538.985627            50.388348  0.651174   1.984202   \n",
      "1  Image2   4.398331   834.853030            28.893823  0.953532   6.495203   \n",
      "2  Image3   3.244263   642.059166            25.338886  0.966065   7.772860   \n",
      "3  Image4   8.511353  1126.214187            33.559115  0.868765   3.763142   \n",
      "4  Image5  21.000793  2235.316978            47.279139  0.684724   1.936029   \n",
      "\n",
      "    kurtosis   contraste   energia       asm  homogeneidad  disiminitud  \\\n",
      "0   5.421042  181.467713  0.781557  0.610831      0.847033     2.765411   \n",
      "1  43.349355   76.745886  0.972770  0.946281      0.980762     0.548605   \n",
      "2  61.756034   81.752406  0.980161  0.960715      0.985066     0.540411   \n",
      "3  15.107579  362.291213  0.921786  0.849690      0.949295     2.765725   \n",
      "4   4.722343  312.439226  0.804184  0.646711      0.880301     3.006660   \n",
      "\n",
      "   correlacion        psnr      ssim       mse        dc  tipo  \n",
      "0     0.968576   97.974630  0.777011  0.171163  0.303989     1  \n",
      "1     0.959751  110.346597  0.977953  0.009913  0.839019     1  \n",
      "2     0.944259  112.266298  0.985362  0.006372  0.849775     1  \n",
      "3     0.859027  101.955792  0.881015  0.068437  0.000000     0  \n",
      "4     0.938572   97.639870  0.766308  0.184878  0.000000     0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1275 entries, 0 to 1274\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   imagen               1275 non-null   category\n",
      " 1   media                1275 non-null   float64 \n",
      " 2   varianza             1275 non-null   float64 \n",
      " 3   desviacion.estandar  1275 non-null   float64 \n",
      " 4   entropia             1275 non-null   float64 \n",
      " 5   asimetria            1275 non-null   float64 \n",
      " 6   kurtosis             1275 non-null   float64 \n",
      " 7   contraste            1275 non-null   float64 \n",
      " 8   energia              1275 non-null   float64 \n",
      " 9   asm                  1275 non-null   float64 \n",
      " 10  homogeneidad         1275 non-null   float64 \n",
      " 11  disiminitud          1275 non-null   float64 \n",
      " 12  correlacion          1275 non-null   float64 \n",
      " 13  psnr                 1275 non-null   float64 \n",
      " 14  ssim                 1275 non-null   float64 \n",
      " 15  mse                  1275 non-null   float64 \n",
      " 16  dc                   1275 non-null   float64 \n",
      " 17  tipo                 1275 non-null   int64   \n",
      "dtypes: category(1), float64(16), int64(1)\n",
      "memory usage: 221.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "pasada = os.getcwd()\n",
    "os.chdir(\"C:/Users/rzamoram/Documents/Machine Learning/Métodos Supervisados con Python/Clase 01\")\n",
    "print(os.getcwd())\n",
    "datos = pd.read_csv('tumores.csv',delimiter=',',decimal=\".\")\n",
    "datos['imagen'] = datos['imagen'].astype('category')\n",
    "print(datos.shape)\n",
    "print(datos.head())\n",
    "print(datos.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApMAAAIYCAYAAAAxYWfmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3debxdZX3v8e8vAxAghHlIAiKDOFCQElScq21B1Givtg7XCbRU63i1t2qdeutQ7VUc2ypKVVBwrkbFebhOFRocQCoKMkMAQWYhwDnP/WOv4CEkJHmac05i3u/Xa7+Svfbaaz17r7NPPmcNJ9VaCwAA9Jgx3QMAAGDjJSYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmYZpV1Xur6jXraVl7VNUNVTVzuP/tqnrO+lj2Suu5oar2WmnajKr6XFUdtR7X86GqekPnc1tV7bO+xtJrXbbvXW2vqtpzeE2z1tO4vlRVz1wfywI2bevlmxKwalV1fpJdktyWZCzJfyU5PsmxrbXxJGmtPXcdlvWc1trXVzdPa+3CJFv/90a9Zq21Va3jjUm+0Vr7t8le/8ZkbbfvZKqqv0+yT2vtaSumtdYeNX0jAn6fiEmYfI9trX29quYleViSdya5f5Ij1+dKqmpWa+229bnMddFae+V0rXtDVVUzW2tj0z0OgMnkMDdMkdbata21JUmelOSZVbV/csdDuVW1Y1V9oaquqarfVNV3h8PHJyTZI8nnh0PMfzvhsOezq+rCJN9czaHQvavq1Kq6djgMvf2wrodX1cUTx1hV51fVHw9/n1lVf1dVv6qq66vqtKrafXjs9kPIVTWvqo6vql9X1QVV9eqqmjE89qyq+l5VvbWqrq6q86pqtXvEquqgqvrRsL6PJ9lipccfU1U/Gd6fH1TVAWvz3lfVo6vqx1V1XVVdNOypW928P6+qx0y4P6uqrqyqPxzuf7KqLhvez+9U1X0mzPuhqvrXqjq5qm5M8kcrbd/thu376+H9+EJVLVxpCKvcXqsY57yqOq6qllXVJVX1hhWnN6w03+FJ/i7Jk4avnZ8O028/pD5sp+9X1buH9Z5VVY+csIz5VbVk+Jo8p6r+co1vOrDJEJMwxVprpya5OMlDVvHwy4bHdsro8PjfjZ7Snp7kwoz2cm7dWvunCc95WJJ7JTlsNat8RpKjkszP6HD7u9ZyqC9N8pQkRyTZZljGb1cx37uTzEuy1zCWZ+SOe13vn+QXSXZM8k9JjquqWnkhVbVZks8mOSHJ9kk+meQJEx7/wyT/luSvkuyQ5H1JllTV5mvxWm4cxrVtkkcneV5VPX418540vO4VDktyZWvtR8P9LyXZN8nOSX6U5KMrPf+pGR3yn5vkeys9NiPJB5PcLaMfDm5K8p6V5lnb7fXh4fF9khyU5E+T3Ol8y9bal5O8KcnHh6+dA1ezvPsnOTej7fS6JJ+ZELInZfR1OT/JE5O8aWJsAps2MQnT49KMgmlltybZLcndWmu3tta+21pra1jW37fWbmyt3bSax09orf2stXZjktck+YtV7cFaheckeXVr7Rdt5KettasmzjAs50lJXtlau761dn6StyV5+oTZLmitvX843Pvh4fXtsor1PSDJ7CTvGF77p5L854TH/zLJ+1prp7TWxlprH06yfHjeXWqtfbu1dkZrbby1dnpGcfSw1cx+YpLFVbXlcP+pw7QVy/q34bUuT/L3SQ4cTmFY4XOtte8P67p5pXFc1Vr7dGvtt6216zOKzpXHscbtVVW7JHlUkpcM2/6KJG9P8uQ1vRd34Yr87r3/eEY/ADx62Bv94CQvb63d3Fr7SZIP5I7bGNiEiUmYHguS/GYV0/9vknOSfLWqzq2qV6zFsi5ah8cvyCjYdlyL5e6e5FdrmGfHJJsNy524jgUT7l+24i+ttRV7Nld1Ac/8JJesFM8Tl3u3JC8bDnFfU1XXDGOcv4YxpqruX1XfGg4vX5vkuVnNe9BaOyfJz5M8dgjKxRlicjj0/+bh0P91Sc4fnjZxWavdHlW1ZVW9bzgd4Lok30my7UqxuDbb627D9GUT3ov3ZbS3tNeq3vv5w+03Q/xOfGziNgY2YWISplhVHZLRP8QrHwLNsMfrZa21vZI8NslLJxxOXN0eyjXtudx9wt/3yGjv55UZHfpdsfdtxV7GnSbMe1GSvdew7CuH5d1tpXVcsobnrcqyJAtWOgS+x0rjeWNrbdsJty1bayetxbJPTLIkye6ttXlJ3pvkTofaJ1hxqPtxSf5rCMxktJfycUn+OKND+3sO0ycu6662x8uS7Jfk/q21bZI8dBXPX932muiijPbK7jjhvdimtXafrNqavkaSVb/3lw637atq7kqP9Wxj4PeQmIQpUlXbDBd2fCzJR1prZ6xinsdU1T7DP+rXZfTrhFZcDXx5RuclrqunVdW9h71s/5DkU8Mh518m2WK4OGV2klcnmXj+4QeSvL6q9q2RA6pqh4kLHpbziSRvrKq5VXW3jM61/EjHOP8jo3MAXzRc9PI/ktxvwuPvT/LcYS9jVdVWw9jnrnJpdzQ3o71rN1fV/TKKwrvysYzOQXxeJhziHpazPMlVGYX4m9bqld3x+TcluWY4H/F1q5hnddvrdq21ZUm+muRtw9fVjKrau6pWd+j+8iR71nBh1GrsnNF7P7uq/jyj83BPbq1dlOQHSf6xqrao0UVPz86dzxUFNlFiEibf56vq+oz2Jr0qyTFZ/a8F2jfJ15PckFFc/Utr7dvDY/+Y5NXDYc2/WYf1n5DkQxkdbt4iyYuS0dXlSf46o2i8JKM9lROv7j4mo1D8akZhe1ySOatY/guH556b0d7WEzO6UGadtNZuSfI/kjwrydUZnYv5mQmPL83ovMn3DI+fM8y7Nv46yT8M2+G1Gb2uuxrLsoze/wcm+fiEh47P6BDvJRn9ztAfruX6V3hHRu/hlcNzv7yKeVa5vVbhGRmdYvBfGb0fn8rofNRV+eTw51VV9aPVzHNKRl9/V2Z0LucTJ5wj+5SM9sJemuTfk7yutfa11SwH2MTUms/tB+D3WVU9K6NfiP/g6R4LsPGxZxIAgG5iEgCAbg5zAwDQzZ5JAAC6iUkAALrNmuoV7rjjjm3PPfec6tUCAKyz00477crW2k5rnnPTNeUxueeee2bp0qVTvVoAgHVWVResea5Nm8PcAAB0E5MAAHQTkwAAdJvycyYBABg57bTTFs6YMeOr4+Pj90xS0z2eVWgzZsw4a3x8/E8PPvjgi1c1g5gEAJgmM2bM+Oouu+yy76677lozZmx4B4zHx8dr2bJl+5177rk/Wbx48aOXLFlyysrzbHijBgDYRIyPj99z1113nbUhhmSSzJgxI7vtttuMOXPm7JDkeYsXL77HneaZhnEBADCyQe6RnGjGjBmpqiRpSXa/0+NTPiIAADYYX/7yl7Pffvtln332yZvf/Oa7mrUlmbnyROdMAgBsIE68z33W6/KeeuaZd/n42NhYnv/85+drX/taFi5cmEMOOSSLFy/Ove9977Vehz2TAACbqFNPPTX77LNP9tprr2y22WZ58pOfnM997nPrtAwxCQCwibrkkkuy++6/Ow1y4cKFueSSS9ZpGWISAGAT1Vq707ThYpu1JiYBADZRCxcuzEUXXXT7/Ysvvjjz589fp2WISQCATdQhhxySs88+O+edd15uueWWfOxjH8vixYvXaRmu5gYA2ETNmjUr73nPe3LYYYdlbGwsRx11VO6zjleUi0kAgA3Emn6Vz2Q44ogjcsQRR3Q/32FuAAC6iUkAALqJSQAAuolJAAC6TckFOFV1dJKjk2TH2bPX+/87OVkOPebp0z0EAIAN2pTsmWytHdtaW9RaWzR35sypWCUAAFPAYW4AgE3YUUcdlZ133jn7779/1/P9nkkAgA3EeV9583pd3t0Pe8Ua53nWs56VF7zgBXnGM57RtQ57JgEANmEPfehDs/3223c/X0wCANBNTAIA0E1MAgDQTUwCANBNTAIAbMKe8pSn5NBDD80vfvGLLFy4MMcdd9w6Pd+vBgIA2ECsza/yWd9OOumk/9bz7ZkEAKCbmAQAoJuYBACgm5gEAJg+bXx8fLrHcJfGx8fTWlvt42ISAGCazJgx46xly5aNb6hBOT4+nmXLlo3ffPPNVw6Txlaex9XcAADTZHx8/E8vuOCCU5ctW7ZbVU33cO6ktZabb775N8cff/xJSbZNcsXK84hJAIBpcvDBB1+8ePHivZM8N8kBSVZ/PHl6bZnkpCQ/W/kBMQkAMI2WLFlyU5K3L168eHaSmdM9ntW4dcmSJXc6xJ2ISQCADcKSJUtuTXLrdI9jXbkABwCAbmISAIBuYhIAgG5iEgCAbmISAIBuYhIAgG5iEgCAbmISAIBuYhIAgG5iEgCAbmISAIBuYhIAgG5iEgCAbmISAIBuYhIAgG5iEgCAbmISAIBuYhIAgG5iEgCAbmISAIBuYhIAgG5iEgCAbmISAIBuYhIAgG5iEgCAbmISAIBuYhIAgG5iEgCAbmISAIBuYhIAgG5iEgCAbmISAIBuYhIAgG5iEgCAbmISAIBuUxKTVXV0VS2tqqXXj41NxSoBAJgCUxKTrbVjW2uLWmuL5s6cORWrBABgCjjMDQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQDcxCQBANzEJAEA3MQkAQLcpicmqOrqqllbV0uvHxqZilQAATIEpicnW2rGttUWttUVzZ86cilUCADAFHOYGAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACg25TEZFUdXVVLq2rp9WNjU7FKAACmwJTEZGvt2NbaotbaorkzZ07FKgEAmAIOcwMA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0G3W2sxUVQcmechw97uttZ+uz0H8v2uuybGXXnqn6e/YZ5/stNlmd5h20c035/jLLsvZN92UzWfMyMO23TZP3WWXnHnjjXnfJZfkltbyzF13zaHz5iVJ3nbhhTl03rw8cLgPbFo+8ZWl+ZePfSuXX3Vd7rf/3fOWlz4hl15xTd70/pNz9oVXJEkeeN+984YXPj47bLv1apfzg5/8Kk97xQeSJJ991/NzwD0W5j9++qv8zVs/meW33JbXPe+xeezDD0yS/OXrjs9jH35AFv/RfSf/BQJMszXumayqFyf5aJKdh9tHquqF63MQ99pyy7xgwYK8YMGCPG/+/MyqyryZM7Pd7Nl3mO+W8fG85cILc+Hy5XniTjvlCTvtlM1njF7CJ6+4IvM33zz7b7VVPnr55UmSn91wQ64fGxOSsIk6/ZcX55Xv+Ex22WGbvPyow3PKGefmNe/+XM675Mpst81WeflRh+fhh+yXr3z/zLz5uC+vdjk3L781r3rnZzJn8zt+T3rbh76afXbfOQ86aJ+86f0nJ0m+96Nzcs31vxWSwCZjbfZMPjvJ/VtrNyZJVb0lyX8keff6GsTOm22WnYc9kKdcd11uay0P23bbzKq6w3w/uPbaXH3bbXnObrvlQfPmZbMZv2vh5ePj2XvOnGw/a1Z+csMNGW8tH7n88hw9f/76GiawkTn1jPPSWstTjrhfHv+Ig/L5b/803zz1rLzpJX+WJ/zJwUmSxX9033z+2z/N2RdcvtrlvOOEr2fuVlvkvvfcI5/71k9un/7bm2/JAfstzG47zsu3Tj0rY2PjeeOxX8xbXvqESX9tABuKtYnJSjI24f7YMG1SfPPqq1NJHrHddnd67JLly5MkJ191VT6wbFnmzpyZZ+26ax4wb14etu22OWHYI3n49tvn61dfnbtvsUX2mjNnsoYKbOB2mLdVkmTpmRfkD/ZdkPMvvSqttVx25XXZabu5SZLvnPbLJMn9/uDuq1zGmedcmg8v+UE+dczz8qHPfv8Oj/35YYvy+vd+IUly5J89KB/94inZf98FOeAeCyfrJQFscNYmJj+Y5JSq+veMIvJxSY6bjMFcfsstOfPGG3Pg1lvf6VzJJLmttSTJdrNm5S923jkfvuyyvO/SS3Pg1lvn8B12yAFbb51bW8uOs2fnVeeem9fuuWeOvfTS/OyGG3L3OXPyvAULssUM1xzBpuKIhx6QE08+NSd+8ZSc+MVTsvWWmydJNp89+ta39Mzz84q3fzr777sgL37aI1e5jP/zr5/PEQ/5g2y15Wa54abRD7SXXXlt9ttzlxz5+AflYQffI8tvvS3zd9o2j33Bu/OJt/1VXn7Mp/O9H5+dP9h3QY752ydlyy3u/P0M4PfFGsuqtXZMkiOT/CbJVUmObK29YzIG842rr05L8shhr2RrLbeMj98ekTsOgXn/efNyyDbb5J5bbplbWsvVt92WJJm/+ea52xZb5NO//nUesd12uWj58pxy3XV589575+Lly/P9a6+djGEDG6jNN5uVj7/16HzxX16UL7/3JTlwv92z+Wazssdu2+fUM87Lka/+YPbYbft8+I1HZqs5o9AcHx/P8ltuzW1jowMyy359Tf79Gz/OI456W77y/TOTJM/9h4/k9F9ekiTZa/edcq+9dss7P/L1POWI++UX51+Wk797er703pfklxdcns9+48fT8+IBpsi67KarJC2TdIj7ttby3WuuyQ6zZ+e+W4+uqLzy1ltz5Fln5e0XXZQkeeA222R2Vf7fNdfkm1dfnTNvvDHbzZqVXSbsxbx0+fKcfsMNedT222e8tSwfH8+3rr461912W8aGKAU2DWNj43nD+76YM8+5NB/5wg/z/R+fk6c95gE558IrcuSrP5ix8ZYnHX5Ivvejc/KNH/48SXLqGefnXotfe/vh69e/8PF5z6uemve86ql5wAF7JUle/uzDs88eO92+nl9ddEW+c9rZOerPHpyxsZablt+aj3/p1Fx1zY25bWx86l84wBRa42Huqnptkj9P8umMQvKDVfXJ1tob1nYlVXV0kqOTZMeVrtBe4T+vuy7XjY3lidtvnxm16l7dbvbsPH/Bgpx4+eU54bLLcrcttsgzd901MyfMf8Jll+VJO++c2TNm5ICtt86iuXPz6V//OnvNmZMHu6obNilVySlnnJcTTz41W24xO89YfGj+5lmH5fPf/mluWn5rkuR1/7wkSbJg523zyAfc607LePgh+93+92+dclaS5NAD985222x1+/Q3vO+L+d9HHpbNN5uVhy7aN39y6L3zjhO+ngPusTCPf+RBk/kSAaZdtTXsrauqnyc5qLV283B/TpIftdbu/F13Lew1Z057w1579Tx1yh16zNOnewgAwDTa6/BXntZaWzTd49iQrc1h7vOTbDHh/uZJfjUpowEAYKOyNldzL09yZlV9LaNzJv8kyfeq6l1J0lp70SSODwCADdjaxOS/D7cVvj05QwEAYGOzxphsrX14KgYCAMDGZ7UxWVWfaK39RVWdkdHh7TtorR0wqSMDAGCDd1d7Jl88/PnzJP97wvRK8k+TNiIAADYaq43J1tqy4a/7tNYumPhYVd1zUkcFAMBG4a4Ocz8vyV8n2auqTp/w0Nwk35/sgQEAsOG7q8PcJyb5UpJ/TPKKCdOvb639ZlJHBQDARuGuDnNfm+TaJE+ZuuEAALAxWZv/AQcAAFZJTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0G1KYrKqjq6qpVW19PqxsalYJQAAU2BKYrK1dmxrbVFrbdHcmTOnYpUAAEwBh7kBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6CYmAQDoJiYBAOgmJgEA6DYlMVlVR1fV0qpaev3Y2FSsEgCAKTAlMdlaO7a1tqi1tmjuzJlTsUoAAKaAw9wAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0E5MAAHQTkwAAdBOTAAB0m5KYrKqjq2ppVS29fmxsKlYJAMAUmJKYbK0d21pb1FpbNHfmzKlYJQAAU8BhbgAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALqJSQAAuolJAAC6iUkAALpVa23yV1J1dJKjk2SPPfY4+IILLpj0dQIA/HdV1WmttUXTPY4N2ZTsmWytHdtaW9RaW7TTTjtNxSoBAJgCDnMDANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0E1MAgDQTUwCANBNTAIA0K1aa1O7wqrrk/xiSlfK+rRjkiunexB0se02brbfxs3223jt11qbO92D2JDNmoZ1/qK1tmga1st6UFVLbb+Nk223cbP9Nm6238arqpZO9xg2dA5zAwDQTUwCANBtOmLy2GlYJ+uP7bfxsu02brbfxs3223jZdmsw5RfgAADw+8NhbgAAuk1aTFbV4VX1i6o6p6peMUz7aFWdXlVvmjDfa6rqcZM1DtZOVe1eVd+qqp9X1ZlV9eJh+vZV9bWqOnv4c7th+hOG+b5bVTsM0/auqo9N5+vYlFXVzKr6cVV9Ybh/96o6Zdh2H6+qzYbpL6yqn1XVyROmPbiqjpnO8W/KqmrbqvpUVZ01fAYP9dnbOFTV/xq2x8+q6qSq2sJnb8NVVf9WVVdU1c8mTFvdZ62q6l1Dx5xeVX84TN+vqk6rqp9W1aHDtFlV9fWq2nJ6Xtn0mpSYrKqZSf45yaOS3DvJU6rqgCRprR2Q5CFVNa+qdktyv9ba5yZjHKyT25K8rLV2ryQPSPL8qrp3klck+UZrbd8k3xjuJ8nLhvmOT/LUYdobkrxmSkfNRC9O8vMJ99+S5O3Dtrs6ybOH6c9JckCSHyc5rKoqo+32+ikcK3f0ziRfbq3dM8mBGW1Hn70NXFUtSPKiJItaa/snmZnkyfHZ25B9KMnhK01b3WftUUn2HW5HJ/nXYfpfDfM8McnfDNOel+SE1tpvJ23kG7DJ2jN5vyTntNbOba3dkuRjSR6dZE5VzUiyWZKxJP+Q5LWTNAbWQWttWWvtR8Pfr8/oH7MFSR6X5MPDbB9O8vjh7+NJNk+yZZJbq+ohSZa11s6e0oGTJKmqhRl9xj4w3K8kj0jyqWGWidsuSWZn2HZJnp7k5McaaZ0AAAQdSURBVNba1VM2YG5XVdskeWiS45KktXZLa+2a+OxtLGZl9G/brIy2ybL47G2wWmvfSfKblSav7rP2uCTHt5EfJtl22Al2a5I5+d1ncNskj83oB7xN0mT90vIFSS6acP/iJPdPcmGSHyU5Ick+GV0A9ONJGgOdqmrPJAclOSXJLq21ZckoOKtq52G2/5PkK0kuTfK0JJ/I6Cdypsc7kvxtkhX/S8MOSa5prd023L84o89lkrw1yQ+TnJnk+0k+mzv/pM7U2SvJr5N8sKoOTHJaRnuZffY2cK21S6rqrRn923ZTkq9mtP189jYuq/usraplFmR05PX4jH6o+6uMdoq9sW3CVzRP1p7JWsW01lp7SWvtvq21t2W0W/+1VfWqqvpEVf3lJI2FdVBVWyf5dJKXtNauW918rbWvtdYObq09NqOf4k5Ost9w3tf7N9XzRqZDVT0myRWttdMmTl7FrC1JWmsntNYOaq09LclLk7wryaOGbff24egBU2dWkj9M8q+ttYOS3JjfHWa7E5+9Dcdwbt3jktw9yfwkW2V0aHRlPnsbp9W1zIWttYe31g5N8tuMtv1ZVXXCcI7sPaZ2mNNvsr5wL06y+4T7CzP6KTpJUqMLbpZm9MHbv7X2F0me7pvg9Kqq2RmF5Edba58ZJl8+7NbP8OcVKz1nyyTPTPIvSf4xyVEZ/WT+P6dq3ORBSRZX1fkZnVLyiIz2VG47HHpLVvoMJklVzU9yyHDO8quTPCnJ8iSPnKJxM3Jxkotba6cM9z+VUVz67G34/jjJea21X7fWbk3ymSQPjM/exmZ1n7W7bJnBGzM67/VFST6a5HXDbZMyWTH5n0n2Ha5o2yyjQzBLktuD5cVJ/m9G5xus2C284lxKpsFwjt1xSX7eWpt4ZeGSjP7ByvDnyhdL/W2Sdw7fSOdktD3HM9q2TIHW2itbawtba3tm9Fn7Zmvtfyb5VkYniCer3navz+8u2rDtpklr7bIkF1XVfsOkRyb5r/jsbQwuTPKAqtpy+B66Ytv57G1cVvdZW5LkGcNV3Q9Icu2Kw+FJUlUPS3LJcL7ylhltw7FsituxtTYptyRHJPllkl8ledWE6S9J8szh75XkpCRnJHnLZI3Fba2214Mz+oZ2epKfDLcjMjr37htJzh7+3H7Cc+Yn+cKE+3+e350LtNN0v6ZN8Zbk4Su2SUbn4p2a5Jwkn0yy+YT5Dkpy3IT7Lxm23Zcnzuc2ZdvtvhkdrTk9o/PotvPZ2zhuGZ3DelaSn2V0PcDmPnsb7m1ojmUZXURzcUZX2q/yszY0yj8PHXNGRlftZ8JjX0uy3XD/XhldE3J6kgdN9+uc6pv/AQcAgG5O9gUAoJuYBACgm5gEAKCbmAQAoJuYBACgm5gEAKCbmAQAoJuYBACg2/8HR4NtwcNE0x8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distribucion_variable_predecir(datos,\"tipo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problema muy desequilibrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       media     varianza  desviacion.estandar  entropia  asimetria  \\\n",
      "0  23.448517  2538.985627            50.388348  0.651174   1.984202   \n",
      "1   4.398331   834.853030            28.893823  0.953532   6.495203   \n",
      "2   3.244263   642.059166            25.338886  0.966065   7.772860   \n",
      "3   8.511353  1126.214187            33.559115  0.868765   3.763142   \n",
      "4  21.000793  2235.316978            47.279139  0.684724   1.936029   \n",
      "\n",
      "    kurtosis   contraste   energia       asm  homogeneidad  disiminitud  \\\n",
      "0   5.421042  181.467713  0.781557  0.610831      0.847033     2.765411   \n",
      "1  43.349355   76.745886  0.972770  0.946281      0.980762     0.548605   \n",
      "2  61.756034   81.752406  0.980161  0.960715      0.985066     0.540411   \n",
      "3  15.107579  362.291213  0.921786  0.849690      0.949295     2.765725   \n",
      "4   4.722343  312.439226  0.804184  0.646711      0.880301     3.006660   \n",
      "\n",
      "   correlacion        psnr      ssim       mse        dc  \n",
      "0     0.968576   97.974630  0.777011  0.171163  0.303989  \n",
      "1     0.959751  110.346597  0.977953  0.009913  0.839019  \n",
      "2     0.944259  112.266298  0.985362  0.006372  0.849775  \n",
      "3     0.859027  101.955792  0.881015  0.068437  0.000000  \n",
      "4     0.938572   97.639870  0.766308  0.184878  0.000000  \n",
      "   tipo\n",
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     0\n",
      "4     0\n"
     ]
    }
   ],
   "source": [
    "X = datos.iloc[:,1:17] \n",
    "print(X.head())\n",
    "y = datos.iloc[:,17:18] \n",
    "print(y.head())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones en Testing son: [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "##Bosques\n",
    "instancia_bosque = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "\n",
    "instancia_bosque.fit(X_train,y_train.iloc[:,0].values)\n",
    "\n",
    "print(\"Las predicciones en Testing son: {}\".format(instancia_bosque.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[ 30   3]\n",
      " [  4 346]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9817232375979112\n",
      "\n",
      "Error Global:\n",
      "0.018276762402088753\n",
      "\n",
      "Precisión por categoría:\n",
      "          0         1\n",
      "0  0.909091  0.988571\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9885714285714285\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9090909090909091\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.09090909090909094\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.011428571428571455\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9914040114613181\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "prediccion = instancia_bosque.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02356101 0.0463508  0.01405155 0.05246964 0.01572265 0.0375766\n",
      " 0.0027295  0.00843819 0.00740019 0.04603719 0.01636483 0.02320525\n",
      " 0.02936465 0.05954844 0.02948095 0.58769855]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x1ff83a90e88>,\n",
       "  <matplotlib.axis.YTick at 0x1ff895746c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89638908>,\n",
       "  <matplotlib.axis.YTick at 0x1ff897344c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89734e48>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89726708>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89726d08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff895faf48>,\n",
       "  <matplotlib.axis.YTick at 0x1ff895df908>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8966fc08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff895df7c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff895f2548>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8a7105c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8a734108>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8a7146c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8a7142c8>],\n",
       " <a list of 16 Text yticklabel objects>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importancia = instancia_bosque.feature_importances_\n",
    "print(importancia)\n",
    "etiquetas = X_train.columns.values\n",
    "y_pos = np.arange(len(etiquetas))\n",
    "plt.barh(y_pos, importancia, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones en Testing son: [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "###XGBoosting\n",
    "instancia_potenciacion = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "print(\"Las predicciones en Testing son: {}\".format(instancia_potenciacion.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[ 26   7]\n",
      " [  2 348]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9765013054830287\n",
      "\n",
      "Error Global:\n",
      "0.023498694516971286\n",
      "\n",
      "Precisión por categoría:\n",
      "          0         1\n",
      "0  0.787879  0.994286\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9942857142857143\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.7878787878787878\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.21212121212121215\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.005714285714285672\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9802816901408451\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.02537333 0.04276316 0.\n",
      " 0.         0.01464124 0.03340622 0.01148433 0.01080906 0.01249665\n",
      " 0.02512731 0.01984939 0.04526759 0.75878172]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x1ff89653c08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89673908>,\n",
       "  <matplotlib.axis.YTick at 0x1ff896e2708>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8916d748>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8916d808>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8916da88>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8915f5c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89158748>,\n",
       "  <matplotlib.axis.YTick at 0x1ff891581c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89148e08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89395b48>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89158908>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8916dfc8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89122e48>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8916aa08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff88db6388>],\n",
       " <a list of 16 Text yticklabel objects>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importancia = instancia_potenciacion.feature_importances_\n",
    "print(importancia)\n",
    "etiquetas = X_train.columns.values\n",
    "y_pos = np.arange(len(etiquetas))\n",
    "plt.barh(y_pos, importancia, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones en Testing son: [1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "###ADA Boosting\n",
    "instancia_potenciacion = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "print(\"Las predicciones en Testing son: {}\".format(instancia_potenciacion.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[ 30   3]\n",
      " [  3 347]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9843342036553525\n",
      "\n",
      "Error Global:\n",
      "0.015665796344647487\n",
      "\n",
      "Precisión por categoría:\n",
      "          0         1\n",
      "0  0.909091  0.991429\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9914285714285714\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9090909090909091\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.09090909090909094\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.008571428571428563\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9914285714285714\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.1 0.3 0.1 0.  0.1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x1ff8a733b88>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8961ba08>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8a71f108>,\n",
       "  <matplotlib.axis.YTick at 0x1ff896fcb88>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89728208>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89728988>,\n",
       "  <matplotlib.axis.YTick at 0x1ff897201c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89720988>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89714188>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89714988>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8970f608>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89720bc8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff8970fec8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff897196c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff897060c8>,\n",
       "  <matplotlib.axis.YTick at 0x1ff89706cc8>],\n",
       " <a list of 16 Text yticklabel objects>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importancia = instancia_potenciacion.feature_importances_\n",
    "print(importancia)\n",
    "etiquetas = X_train.columns.values\n",
    "y_pos = np.arange(len(etiquetas))\n",
    "plt.barh(y_pos, importancia, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, etiquetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Usando la funci´on programada en el ejercicio 1 de la tarea anterior, los datos tumores.csv y los modelos generados arriba construya un DataFrame de manera que en cada una de las filas aparezca un modelo predictivo y en las columnas aparezcan los ´ındices Precisi´on Global, Error Global Precisi´on Positiva (PP), Precisi´on Negativa (PN), Falsos Positivos (FP), los Falsos Negativos (FN), la Asertividad Positiva (AP) y la Asertividad Negativa (AN). ¿Cu´al de los modelos es mejor para estos datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[ 30   3]\n",
      " [  4 346]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9817232375979112\n",
      "\n",
      "Error Global:\n",
      "0.018276762402088753\n",
      "\n",
      "Precisión por categoría:\n",
      "          0         1\n",
      "0  0.909091  0.988571\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9885714285714285\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9090909090909091\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.09090909090909094\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.011428571428571455\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9914040114613181\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "##Bosques\n",
    "instancia_bosque = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "instancia_bosque.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_bosque.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[ 26   7]\n",
      " [  2 348]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9765013054830287\n",
      "\n",
      "Error Global:\n",
      "0.023498694516971286\n",
      "\n",
      "Precisión por categoría:\n",
      "          0         1\n",
      "0  0.787879  0.994286\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9942857142857143\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.7878787878787878\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.21212121212121215\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.005714285714285672\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9802816901408451\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "###XGBoosting\n",
    "instancia_potenciacion = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[ 30   3]\n",
      " [  3 347]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9843342036553525\n",
      "\n",
      "Error Global:\n",
      "0.015665796344647487\n",
      "\n",
      "Precisión por categoría:\n",
      "          0         1\n",
      "0  0.909091  0.991429\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9914285714285714\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9090909090909091\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.09090909090909094\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.008571428571428563\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9914285714285714\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "###ADA Boosting\n",
    "instancia_potenciacion = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precisi´on Global</th>\n",
       "      <th>Error Global</th>\n",
       "      <th>Precisi´on Positiva (PP)</th>\n",
       "      <th>Precisi´on Negativa (PN)</th>\n",
       "      <th>Falsos Positivos (FP)</th>\n",
       "      <th>Falsos Negativos (FN)</th>\n",
       "      <th>Asertividad Positiva (AP)</th>\n",
       "      <th>Asertividad Negativa (AN)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K-vecinos</th>\n",
       "      <td>0.898172</td>\n",
       "      <td>0.101828</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.025714</td>\n",
       "      <td>0.919137</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision</th>\n",
       "      <td>0.984334</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosques aleatorios</th>\n",
       "      <td>0.981723</td>\n",
       "      <td>0.018277</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.991404</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting</th>\n",
       "      <td>0.976501</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>0.994286</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.980282</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA Boosting</th>\n",
       "      <td>0.984334</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Precisi´on Global  Error Global  Precisi´on Positiva (PP)  \\\n",
       "K-vecinos                    0.898172      0.101828                  0.974286   \n",
       "Arbol de Decision            0.984334      0.015666                  0.991429   \n",
       "Bosques aleatorios           0.981723      0.018277                  0.988571   \n",
       "XGBoosting                   0.976501      0.023499                  0.994286   \n",
       "ADA Boosting                 0.984334      0.015666                  0.991429   \n",
       "\n",
       "                    Precisi´on Negativa (PN)  Falsos Positivos (FP)  \\\n",
       "K-vecinos                           0.090909               0.909091   \n",
       "Arbol de Decision                   0.909091               0.090909   \n",
       "Bosques aleatorios                  0.909091               0.090909   \n",
       "XGBoosting                          0.787879               0.212121   \n",
       "ADA Boosting                        0.909091               0.090909   \n",
       "\n",
       "                    Falsos Negativos (FN)  Asertividad Positiva (AP)  \\\n",
       "K-vecinos                        0.025714                   0.919137   \n",
       "Arbol de Decision                0.008571                   0.991429   \n",
       "Bosques aleatorios               0.011429                   0.991404   \n",
       "XGBoosting                       0.005714                   0.980282   \n",
       "ADA Boosting                     0.008571                   0.991429   \n",
       "\n",
       "                    Asertividad Negativa (AN)  \n",
       "K-vecinos                            0.250000  \n",
       "Arbol de Decision                    0.909091  \n",
       "Bosques aleatorios                   0.882353  \n",
       "XGBoosting                           0.928571  \n",
       "ADA Boosting                         0.909091  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.matrix([[0.8981723237597912, 0.10182767624020883, 0.9742857142857143, 0.09090909090909091, 0.9090909090909091, 0.02571428571428569, 0.9191374663072777, 0.25],\n",
    "               [0.9843342036553525, 0.015665796344647487, 0.9914285714285714, 0.9090909090909091, 0.09090909090909094, 0.008571428571428563, 0.9914285714285714, 0.9090909090909091],\n",
    "               [0.9817232375979112, 0.018276762402088753, 0.9885714285714285, 0.9090909090909091, 0.09090909090909094, 0.011428571428571455, 0.9914040114613181, 0.8823529411764706],\n",
    "               [0.9765013054830287, 0.023498694516971286, 0.9942857142857143, 0.7878787878787878, 0.21212121212121215, 0.005714285714285672, 0.9802816901408451, 0.9285714285714286],\n",
    "               [0.9843342036553525, 0.015665796344647487, 0.9914285714285714, 0.9090909090909091, 0.09090909090909094, 0.008571428571428563, 0.9914285714285714, 0.9090909090909091]])\n",
    "mi_df = pd.DataFrame(A)\n",
    "nombres_filas = [\"K-vecinos\", \"Arbol de Decision\", \"Bosques aleatorios\", \"XGBoosting\", \"ADA Boosting\"]\n",
    "nombres_columnas = [\"Precisi´on Global\",\"Error Global\",\"Precisi´on Positiva (PP)\", \"Precisi´on Negativa (PN)\", \"Falsos Positivos (FP)\", \"Falsos Negativos (FN)\", \"Asertividad Positiva (AP)\", \"Asertividad Negativa (AN)\"]\n",
    "mi_df = pd.DataFrame(A, index = nombres_filas, columns = nombres_columnas )\n",
    "mi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la tarea 1 de k-vecinos se debe notar que los 4 algoritmos generaron el mismo resultado, por lo que se toma como un resultado default para evitar confusion de interpretacion. La precision global fue de 0.8981723237597912 y la precision global por categoria fue de 0.090909 para el caso de No tumor y 0.974286 para el caso de Si tumor. En el caso de bayes para este ejercicio funciono mucho mejor con una precision global de 0.9843342036553525 y por categoria de 0.909091 y 0.991429 es decir, identifica mejor los casos con ciertos errores de datos confundidos. curiosamente con ADA Boosting ocurre justamente la misma estimacion por lo que estos dos metodos son los que mejor predicen los datos de los tumores. Pero cabe destacar que XGBoosting es el que menor cantidad de tumores clasifica como no tumores por lo que en dado caso este modelo tambien funcionaria bien y quizas mejor para efectos del problema. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Repita los ejercicios 1-2, pero esta vez use una combinaci´on de los par´ametros del m´etodo de cada uno de los m´etodos citados arriba. ¿Mejora la predicci´on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso viendo lo que sucedio en los ejercicios anteriores parece que entre mayor cantidad de estimadores y profundidad maxima sirve mejor por lo que estos son los parametros que parecen formar la gran combinacion (n_estimators=1000, max_depth=250, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[ 33   0]\n",
      " [  3 347]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9921671018276762\n",
      "\n",
      "Error Global:\n",
      "0.007832898172323799\n",
      "\n",
      "Precisión por categoría:\n",
      "     0         1\n",
      "0  1.0  0.991429\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9914285714285714\n",
      "\n",
      "Precision Negativa (PN):\n",
      "1.0\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.0\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.008571428571428563\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "1.0\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "##Bosques\n",
    "instancia_bosque = RandomForestClassifier(n_estimators=1000, max_depth=250, random_state=0)\n",
    "instancia_bosque.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_bosque.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[ 30   3]\n",
      " [  3 347]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9843342036553525\n",
      "\n",
      "Error Global:\n",
      "0.015665796344647487\n",
      "\n",
      "Precisión por categoría:\n",
      "          0         1\n",
      "0  0.909091  0.991429\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9914285714285714\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9090909090909091\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.09090909090909094\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.008571428571428563\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9914285714285714\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "###XGBoosting\n",
    "instancia_potenciacion = GradientBoostingClassifier(n_estimators=1000, max_depth=250, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[ 31   2]\n",
      " [  3 347]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9869451697127938\n",
      "\n",
      "Error Global:\n",
      "0.01305483028720622\n",
      "\n",
      "Precisión por categoría:\n",
      "          0         1\n",
      "0  0.939394  0.991429\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.9914285714285714\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9393939393939394\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.06060606060606055\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.008571428571428563\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.994269340974212\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9117647058823529\n"
     ]
    }
   ],
   "source": [
    "###ADA Boosting\n",
    "instancia_potenciacion = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "instancia_potenciacion.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_potenciacion.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general_extra(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precisi´on Global</th>\n",
       "      <th>Error Global</th>\n",
       "      <th>Precisi´on Positiva (PP)</th>\n",
       "      <th>Precisi´on Negativa (PN)</th>\n",
       "      <th>Falsos Positivos (FP)</th>\n",
       "      <th>Falsos Negativos (FN)</th>\n",
       "      <th>Asertividad Positiva (AP)</th>\n",
       "      <th>Asertividad Negativa (AN)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>K-vecinos</th>\n",
       "      <td>0.898172</td>\n",
       "      <td>0.101828</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.025714</td>\n",
       "      <td>0.919137</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arbol de Decision</th>\n",
       "      <td>0.984334</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosques aleatorios</th>\n",
       "      <td>0.981723</td>\n",
       "      <td>0.018277</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.991404</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting</th>\n",
       "      <td>0.976501</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>0.994286</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.980282</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA Boosting</th>\n",
       "      <td>0.984334</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosques aleatorios (n_estimators=1000, max_depth=250, random_state=0)</th>\n",
       "      <td>0.992167</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoosting (n_estimators=1000, max_depth=250, random_state=0)</th>\n",
       "      <td>0.984334</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADA Boosting (n_estimators=1000, random_state=0)</th>\n",
       "      <td>0.986945</td>\n",
       "      <td>0.013055</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.994269</td>\n",
       "      <td>0.911765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Precisi´on Global  \\\n",
       "K-vecinos                                                    0.898172   \n",
       "Arbol de Decision                                            0.984334   \n",
       "Bosques aleatorios                                           0.981723   \n",
       "XGBoosting                                                   0.976501   \n",
       "ADA Boosting                                                 0.984334   \n",
       "Bosques aleatorios (n_estimators=1000, max_dept...           0.992167   \n",
       "XGBoosting (n_estimators=1000, max_depth=250, r...           0.984334   \n",
       "ADA Boosting (n_estimators=1000, random_state=0)             0.986945   \n",
       "\n",
       "                                                    Error Global  \\\n",
       "K-vecinos                                               0.101828   \n",
       "Arbol de Decision                                       0.015666   \n",
       "Bosques aleatorios                                      0.018277   \n",
       "XGBoosting                                              0.023499   \n",
       "ADA Boosting                                            0.015666   \n",
       "Bosques aleatorios (n_estimators=1000, max_dept...      0.007833   \n",
       "XGBoosting (n_estimators=1000, max_depth=250, r...      0.015666   \n",
       "ADA Boosting (n_estimators=1000, random_state=0)        0.013055   \n",
       "\n",
       "                                                    Precisi´on Positiva (PP)  \\\n",
       "K-vecinos                                                           0.974286   \n",
       "Arbol de Decision                                                   0.991429   \n",
       "Bosques aleatorios                                                  0.988571   \n",
       "XGBoosting                                                          0.994286   \n",
       "ADA Boosting                                                        0.991429   \n",
       "Bosques aleatorios (n_estimators=1000, max_dept...                  0.991429   \n",
       "XGBoosting (n_estimators=1000, max_depth=250, r...                  0.991429   \n",
       "ADA Boosting (n_estimators=1000, random_state=0)                    0.991429   \n",
       "\n",
       "                                                    Precisi´on Negativa (PN)  \\\n",
       "K-vecinos                                                           0.090909   \n",
       "Arbol de Decision                                                   0.909091   \n",
       "Bosques aleatorios                                                  0.909091   \n",
       "XGBoosting                                                          0.787879   \n",
       "ADA Boosting                                                        0.909091   \n",
       "Bosques aleatorios (n_estimators=1000, max_dept...                  1.000000   \n",
       "XGBoosting (n_estimators=1000, max_depth=250, r...                  0.909091   \n",
       "ADA Boosting (n_estimators=1000, random_state=0)                    0.939394   \n",
       "\n",
       "                                                    Falsos Positivos (FP)  \\\n",
       "K-vecinos                                                        0.909091   \n",
       "Arbol de Decision                                                0.090909   \n",
       "Bosques aleatorios                                               0.090909   \n",
       "XGBoosting                                                       0.212121   \n",
       "ADA Boosting                                                     0.090909   \n",
       "Bosques aleatorios (n_estimators=1000, max_dept...               0.000000   \n",
       "XGBoosting (n_estimators=1000, max_depth=250, r...               0.090909   \n",
       "ADA Boosting (n_estimators=1000, random_state=0)                 0.060606   \n",
       "\n",
       "                                                    Falsos Negativos (FN)  \\\n",
       "K-vecinos                                                        0.025714   \n",
       "Arbol de Decision                                                0.008571   \n",
       "Bosques aleatorios                                               0.011429   \n",
       "XGBoosting                                                       0.005714   \n",
       "ADA Boosting                                                     0.008571   \n",
       "Bosques aleatorios (n_estimators=1000, max_dept...               0.008571   \n",
       "XGBoosting (n_estimators=1000, max_depth=250, r...               0.008571   \n",
       "ADA Boosting (n_estimators=1000, random_state=0)                 0.008571   \n",
       "\n",
       "                                                    Asertividad Positiva (AP)  \\\n",
       "K-vecinos                                                            0.919137   \n",
       "Arbol de Decision                                                    0.991429   \n",
       "Bosques aleatorios                                                   0.991404   \n",
       "XGBoosting                                                           0.980282   \n",
       "ADA Boosting                                                         0.991429   \n",
       "Bosques aleatorios (n_estimators=1000, max_dept...                   1.000000   \n",
       "XGBoosting (n_estimators=1000, max_depth=250, r...                   0.991429   \n",
       "ADA Boosting (n_estimators=1000, random_state=0)                     0.994269   \n",
       "\n",
       "                                                    Asertividad Negativa (AN)  \n",
       "K-vecinos                                                            0.250000  \n",
       "Arbol de Decision                                                    0.909091  \n",
       "Bosques aleatorios                                                   0.882353  \n",
       "XGBoosting                                                           0.928571  \n",
       "ADA Boosting                                                         0.909091  \n",
       "Bosques aleatorios (n_estimators=1000, max_dept...                   0.916667  \n",
       "XGBoosting (n_estimators=1000, max_depth=250, r...                   0.909091  \n",
       "ADA Boosting (n_estimators=1000, random_state=0)                     0.911765  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.matrix([[0.8981723237597912, 0.10182767624020883, 0.9742857142857143, 0.09090909090909091, 0.9090909090909091, 0.02571428571428569, 0.9191374663072777, 0.25],\n",
    "               [0.9843342036553525, 0.015665796344647487, 0.9914285714285714, 0.9090909090909091, 0.09090909090909094, 0.008571428571428563, 0.9914285714285714, 0.9090909090909091],\n",
    "               [0.9817232375979112, 0.018276762402088753, 0.9885714285714285, 0.9090909090909091, 0.09090909090909094, 0.011428571428571455, 0.9914040114613181, 0.8823529411764706],\n",
    "               [0.9765013054830287, 0.023498694516971286, 0.9942857142857143, 0.7878787878787878, 0.21212121212121215, 0.005714285714285672, 0.9802816901408451, 0.9285714285714286],\n",
    "               [0.9843342036553525, 0.015665796344647487, 0.9914285714285714, 0.9090909090909091, 0.09090909090909094, 0.008571428571428563, 0.9914285714285714, 0.9090909090909091],\n",
    "               [0.9921671018276762, 0.007832898172323799, 0.9914285714285714, 1.0, 0.0, 0.008571428571428563, 1.0, 0.9166666666666666],\n",
    "               [0.9843342036553525, 0.015665796344647487, 0.9914285714285714, 0.9090909090909091, 0.09090909090909094, 0.008571428571428563, 0.9914285714285714, 0.9090909090909091],\n",
    "               [0.9869451697127938, 0.01305483028720622, 0.9914285714285714, 0.9393939393939394, 0.06060606060606055, 0.008571428571428563, 0.994269340974212, 0.9117647058823529]])\n",
    "mi_df = pd.DataFrame(A)\n",
    "nombres_filas = [\"K-vecinos\", \"Arbol de Decision\", \"Bosques aleatorios\", \"XGBoosting\", \"ADA Boosting\", \"Bosques aleatorios (n_estimators=1000, max_depth=250, random_state=0)\", \"XGBoosting (n_estimators=1000, max_depth=250, random_state=0)\", \"ADA Boosting (n_estimators=1000, random_state=0)\"]\n",
    "nombres_columnas = [\"Precisi´on Global\",\"Error Global\",\"Precisi´on Positiva (PP)\", \"Precisi´on Negativa (PN)\", \"Falsos Positivos (FP)\", \"Falsos Negativos (FN)\", \"Asertividad Positiva (AP)\", \"Asertividad Negativa (AN)\"]\n",
    "mi_df = pd.DataFrame(A, index = nombres_filas, columns = nombres_columnas )\n",
    "mi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, cambiando los parametros dando un estimador de 1000 con una profundidad de 250, el metodo de Bosques aleatorios arroja una precision global de 0.992167 que lo convierte en la prediccion mas acertada. Pero cabe resaltar que los tumores identificados como no tumores no cambian respecto a los otros dos metodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta 3: [30 puntos] La idea de este ejercicio es programar una Clase en Python para un nuevo m´etodo de Consenso Propio, esto basado en los m´etodos K-vecinos m´as cercanos, Arbo- ´ les de Decisi´on, M´etodo de Potenciaci´on (XGBoosting) y M´etodo de Potenciaci´on (ADABoosting), para esto realice los siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Programe una Clase en Python denominada ConsensoPropio que tiene, adem´as del constructor, al menos los siguientes m´etodos fit(X train, y train, ...) que recibe la tabla de entrenamiento y genera 4 muestras aleatorias con reemplazo (Boostraps) de los\n",
    "datos de aprendizaje y luego aplica en cada una de estas muestras uno de los m´etodos predictivos mencionados arriba. Este m´etodo debe generar un nuevo modelo predictivo que es un atributo de clase, tipo diccionario, que incluya los 4 modelos  generados (todos los m´etodos usar´an todas las variables) y las 4 de precisiones globales, respectivamente de cada modelo1 , que denotamos por (P G1, P G2, . . . , P G4), donde 0 ≤ P Gj ≤ 1 para j = 1, 2, . . . , 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsensoPropio:\n",
    "    def __init__(self,dataset,T,test_dataset):\n",
    "        self.dataset = dataset\n",
    "        self.T = T\n",
    "        self.test_dataset = test_dataset\n",
    "        self.alphas = None\n",
    "        self.models = None\n",
    "        self.accuracy = []\n",
    "        self.predictions = None\n",
    "    def fit(self):\n",
    "        # parte descriptiva\n",
    "        X = self.dataset.drop(['genero'],axis=1)\n",
    "        Y = self.dataset['genero'].where(self.dataset['genero']==1,-1)\n",
    "        # los pesos \n",
    "        evalua = pd.DataFrame(Y.copy())\n",
    "        evalua['weights'] = 1/len(self.dataset) \n",
    "        # corre el algoritmo\n",
    "        alphas = [] \n",
    "        models = []\n",
    "        for t in range(self.T):\n",
    "            \n",
    "            ##Arbol de decision\n",
    "            Tree_model = DecisionTreeClassifier(criterion=\"entropy\",max_depth=1) \n",
    "            model = Tree_model.fit(X,Y,sample_weight=np.array(evalua['weights'])) \n",
    "            models.append(model)\n",
    "            predictions = model.predict(X)\n",
    "            score = model.score(X,Y)\n",
    "            evalua['predictions'] = predictions\n",
    "            evalua['evalua'] = np.where(evalua['predictions'] == evalua['target'],1,0)\n",
    "            evalua['misclassified'] = np.where(evalua['predictions'] != evalua['target'],1,0)\n",
    "            accuracy = sum(evalua['evalua'])/len(evalua['evalua'])\n",
    "            misclassification = sum(evalua['misclassified'])/len(evalua['misclassified'])\n",
    "            err = np.sum(evalua['weights']*evalua['misclassified'])/np.sum(evalua['weights'])\n",
    "            alpha = np.log((1-err)/err)\n",
    "            alphas.append(alpha)\n",
    "            evalua['weights'] *= np.exp(alpha*evalua['misclassified'])\n",
    "            \n",
    "            ##Kneighbors\n",
    "            kneighbor = KNeighborsClassifier(n_neighbors=3)\n",
    "            model2 = kneighbor.fit(X,Y,sample_weight=np.array(evalua['weights'])) \n",
    "            model2.append(model2)\n",
    "            predictions2 = model2.predict(X)\n",
    "            score2 = model2.score(X,Y)\n",
    "            evalua['predictions'] = predictions2\n",
    "            evalua['evalua'] = np.where(evalua['predictions'] == evalua['target'],1,0)\n",
    "            evalua['misclassified'] = np.where(evalua['predictions'] != evalua['target'],1,0)\n",
    "            accuracy2 = sum(evalua['evalua'])/len(evalua['evalua'])\n",
    "            misclassification2 = sum(evalua['misclassified'])/len(evalua['misclassified'])\n",
    "            err2 = np.sum(evalua['weights']*evalua['misclassified'])/np.sum(evalua['weights'])\n",
    "            alpha2 = np.log((1-err2)/err2)\n",
    "            alphas2.append(alpha2)\n",
    "            evalua['weights'] *= np.exp(alpha2*evalua['misclassified'])\n",
    "            \n",
    "            ###XGBoosting\n",
    "            xgboosting = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
    "            model3 = xgboosting.fit(X,Y,sample_weight=np.array(evalua['weights'])) \n",
    "            model3.append(model3)\n",
    "            predictions3 = model3.predict(X)\n",
    "            score3 = model3.score(X,Y)\n",
    "            evalua['predictions'] = predictions3\n",
    "            evalua['evalua'] = np.where(evalua['predictions'] == evalua['target'],1,0)\n",
    "            evalua['misclassified'] = np.where(evalua['predictions'] != evalua['target'],1,0)\n",
    "            accuracy3 = sum(evalua['evalua'])/len(evalua['evalua'])\n",
    "            misclassification3 = sum(evalua['misclassified'])/len(evalua['misclassified'])\n",
    "            err3 = np.sum(evalua['weights']*evalua['misclassified'])/np.sum(evalua['weights'])\n",
    "            alpha3 = np.log((1-err3)/err3)\n",
    "            alphas3.append(alpha3)\n",
    "            evalua['weights'] *= np.exp(alpha3*evalua['misclassified'])      \n",
    "        \n",
    "            ###ADA Boosting\n",
    "            ada = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "            model4 = ada.fit(X,Y,sample_weight=np.array(evalua['weights'])) \n",
    "            model4.append(model4)\n",
    "            predictions4 = model4.predict(X)\n",
    "            score4 = model4.score(X,Y)\n",
    "            evalua['predictions'] = predictions4\n",
    "            evalua['evalua'] = np.where(evalua['predictions'] == evalua['target'],1,0)\n",
    "            evalua['misclassified'] = np.where(evalua['predictions'] != evalua['target'],1,0)\n",
    "            accuracy4 = sum(evalua['evalua'])/len(evalua['evalua'])\n",
    "            misclassification4 = sum(evalua['misclassified'])/len(evalua['misclassified'])\n",
    "            err4 = np.sum(evalua['weights']*evalua['misclassified'])/np.sum(evalua['weights'])\n",
    "            alpha4 = np.log((1-err4)/err4)\n",
    "            alphas4.append(alpha4)\n",
    "            evalua['weights'] *= np.exp(alpha4*evalua['misclassified'])\n",
    "        \n",
    "        \n",
    "        self.alphas = alphas\n",
    "        self.models = models\n",
    "        \n",
    "        self.alpha2 = alpha2\n",
    "        self.models2 = model2\n",
    "        \n",
    "        self.alpha3 = alpha3\n",
    "        self.models3 = model3\n",
    "        \n",
    "        self.alpha4 = alpha4\n",
    "        self.models4 = model4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Programe una funci´on predict(X test) que recibe la tabla de testing. Luego, para predecir aplica en cada una de las filas de la tabla de testing los 4 modelos predictivos que est´an almacenados dentro de la Clase en el atributo incluido para este efecto; y se establece un consenso de todos los resultados. Se debe programar una f´ormula en Python que le d´e mayor importancia a los m´etodos con mejor precisi´on global. Si denotamos por Mj (h, i) la probabilidad que retorna el j-´esimo modelo en el individuo i-´esimo para la categor´ıa h de variable a predecir, donde j var´ıa de 1 hasta 4, h var´ıa desde 1 hasta p=n´umero de categor´ıas de la variable a predecir e i var´ıa de 1 hasta s = cantidad de individuos en la tabla de testing, esta f´ormula de define como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsensoPropio:\n",
    "    def __init__(self,dataset,T,test_dataset):\n",
    "        self.dataset = dataset\n",
    "        self.T = T\n",
    "        self.test_dataset = test_dataset\n",
    "        self.alphas = None\n",
    "        self.models = None\n",
    "        self.accuracy = []\n",
    "        self.predictions = None\n",
    "    def fit(self):\n",
    "        # parte descriptiva\n",
    "        X = self.dataset.drop(['genero'],axis=1)\n",
    "        Y = self.dataset['genero'].where(self.dataset['genero']==1,-1)\n",
    "        # los pesos \n",
    "        evalua = pd.DataFrame(Y.copy())\n",
    "        evalua['weights'] = 1/len(self.dataset) \n",
    "        # corre el algoritmo\n",
    "        alphas = [] \n",
    "        models = []\n",
    "        for t in range(self.T):\n",
    "            \n",
    "            ##Arbol de decision\n",
    "            Tree_model = DecisionTreeClassifier(criterion=\"entropy\",max_depth=1) \n",
    "            model = Tree_model.fit(X,Y,sample_weight=np.array(evalua['weights'])) \n",
    "            models.append(model)\n",
    "            predictions = model.predict(X)\n",
    "            score = model.score(X,Y)\n",
    "            evalua['predictions'] = predictions\n",
    "            evalua['evalua'] = np.where(evalua['predictions'] == evalua['target'],1,0)\n",
    "            evalua['misclassified'] = np.where(evalua['predictions'] != evalua['target'],1,0)\n",
    "            accuracy = sum(evalua['evalua'])/len(evalua['evalua'])\n",
    "            misclassification = sum(evalua['misclassified'])/len(evalua['misclassified'])\n",
    "            err = np.sum(evalua['weights']*evalua['misclassified'])/np.sum(evalua['weights'])\n",
    "            alpha = np.log((1-err)/err)\n",
    "            alphas.append(alpha)\n",
    "            evalua['weights'] *= np.exp(alpha*evalua['misclassified'])\n",
    "            \n",
    "            ##Kneighbors\n",
    "            kneighbor = KNeighborsClassifier(n_neighbors=3)\n",
    "            model2 = kneighbor.fit(X,Y,sample_weight=np.array(evalua['weights'])) \n",
    "            model2.append(model2)\n",
    "            predictions2 = model2.predict(X)\n",
    "            score2 = model2.score(X,Y)\n",
    "            evalua['predictions'] = predictions2\n",
    "            evalua['evalua'] = np.where(evalua['predictions'] == evalua['target'],1,0)\n",
    "            evalua['misclassified'] = np.where(evalua['predictions'] != evalua['target'],1,0)\n",
    "            accuracy2 = sum(evalua['evalua'])/len(evalua['evalua'])\n",
    "            misclassification2 = sum(evalua['misclassified'])/len(evalua['misclassified'])\n",
    "            err2 = np.sum(evalua['weights']*evalua['misclassified'])/np.sum(evalua['weights'])\n",
    "            alpha2 = np.log((1-err2)/err2)\n",
    "            alphas2.append(alpha2)\n",
    "            evalua['weights'] *= np.exp(alpha2*evalua['misclassified'])\n",
    "            \n",
    "            ###XGBoosting\n",
    "            xgboosting = GradientBoostingClassifier(n_estimators=10, random_state=0)\n",
    "            model3 = xgboosting.fit(X,Y,sample_weight=np.array(evalua['weights'])) \n",
    "            model3.append(model3)\n",
    "            predictions3 = model3.predict(X)\n",
    "            score3 = model3.score(X,Y)\n",
    "            evalua['predictions'] = predictions3\n",
    "            evalua['evalua'] = np.where(evalua['predictions'] == evalua['target'],1,0)\n",
    "            evalua['misclassified'] = np.where(evalua['predictions'] != evalua['target'],1,0)\n",
    "            accuracy3 = sum(evalua['evalua'])/len(evalua['evalua'])\n",
    "            misclassification3 = sum(evalua['misclassified'])/len(evalua['misclassified'])\n",
    "            err3 = np.sum(evalua['weights']*evalua['misclassified'])/np.sum(evalua['weights'])\n",
    "            alpha3 = np.log((1-err3)/err3)\n",
    "            alphas3.append(alpha3)\n",
    "            evalua['weights'] *= np.exp(alpha3*evalua['misclassified'])      \n",
    "        \n",
    "            ###ADA Boosting\n",
    "            ada = AdaBoostClassifier(n_estimators=10, random_state=0)\n",
    "            model4 = ada.fit(X,Y,sample_weight=np.array(evalua['weights'])) \n",
    "            model4.append(model4)\n",
    "            predictions4 = model4.predict(X)\n",
    "            score4 = model4.score(X,Y)\n",
    "            evalua['predictions'] = predictions4\n",
    "            evalua['evalua'] = np.where(evalua['predictions'] == evalua['target'],1,0)\n",
    "            evalua['misclassified'] = np.where(evalua['predictions'] != evalua['target'],1,0)\n",
    "            accuracy4 = sum(evalua['evalua'])/len(evalua['evalua'])\n",
    "            misclassification4 = sum(evalua['misclassified'])/len(evalua['misclassified'])\n",
    "            err4 = np.sum(evalua['weights']*evalua['misclassified'])/np.sum(evalua['weights'])\n",
    "            alpha4 = np.log((1-err4)/err4)\n",
    "            alphas4.append(alpha4)\n",
    "            evalua['weights'] *= np.exp(alpha4*evalua['misclassified'])\n",
    "        \n",
    "        \n",
    "        self.alphas = alphas\n",
    "        self.models = models\n",
    "        \n",
    "        self.alpha2 = alpha2\n",
    "        self.models2 = model2\n",
    "        \n",
    "        self.alpha3 = alpha3\n",
    "        self.models3 = model3\n",
    "        \n",
    "        self.alpha4 = alpha4\n",
    "        self.models4 = model4\n",
    "            \n",
    "    def predict(self):\n",
    "        X_test = self.test_dataset.drop(['genero'],axis=1).reindex(range(len(self.test_dataset)))\n",
    "        Y_test = self.test_dataset['genero'].reindex(range(len(self.test_dataset))).where(self.dataset['genero']==1,-1)\n",
    "        \n",
    "        accuracy = []\n",
    "        predictions = []\n",
    "        \n",
    "        for alpha,model in zip(self.alphas,self.models):\n",
    "            prediction = alpha*model.predict(X_test) # We use the predict method for the single decisiontreeclassifier models in the list\n",
    "            predictions.append(prediction)\n",
    "            self.accuracy.append(np.sum(np.sign(np.sum(np.array(predictions),axis=0))==Y_test.values)/len(predictions[0]))\n",
    "            \n",
    "        self.predictions = np.sign(np.sum(np.array(predictions),axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Usando la tabla de datos voces.csv genere al azar una tabla de testing con un 20 % de los datos y con el resto de los datos construya una tabla de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rzamoram\\Documents\\Machine Learning\\Métodos Supervisados con Python\\Clase 01\n",
      "(3168, 21)\n",
      "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
      "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
      "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
      "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
      "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
      "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
      "\n",
      "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
      "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
      "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
      "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
      "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
      "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
      "\n",
      "     maxfun   meandom    mindom    maxdom   dfrange   modindx     genero  \n",
      "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000  Masculino  \n",
      "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632  Masculino  \n",
      "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512  Masculino  \n",
      "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119  Masculino  \n",
      "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274  Masculino  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  genero    3168 non-null   object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "pasada = os.getcwd()\n",
    "os.chdir(\"C:/Users/rzamoram/Documents/Machine Learning/Métodos Supervisados con Python/Clase 01\")\n",
    "print(os.getcwd())\n",
    "datos = pd.read_csv('voces.csv',delimiter=',',decimal=\".\")\n",
    "print(datos.shape)\n",
    "print(datos.head())\n",
    "print(datos.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Genere modelos predictivos usando la Clase ConsensoPropio y el m´etodo fit de la clase RandomForestClassifier (con solamente 4 ´arboles, es decir, 4 boostraps), luego para la tabla de testing calcule, para ambos m´etodos, calcule la precisi´on global, el error global y la precisi´on por clases. ¿Cu´al m´etodo es mejor?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
      "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
      "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
      "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
      "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
      "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
      "\n",
      "          kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \\\n",
      "0   274.402906  0.893369  0.491918  0.000000  0.059781  0.084279  0.015702   \n",
      "1   634.613855  0.892193  0.513724  0.000000  0.066009  0.107937  0.015826   \n",
      "2  1024.927705  0.846389  0.478905  0.000000  0.077316  0.098706  0.015656   \n",
      "3     4.177296  0.963322  0.727232  0.083878  0.151228  0.088965  0.017798   \n",
      "4     4.333713  0.971955  0.783568  0.104261  0.135120  0.106398  0.016931   \n",
      "\n",
      "     maxfun   meandom    mindom    maxdom   dfrange   modindx  \n",
      "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000  \n",
      "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632  \n",
      "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512  \n",
      "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119  \n",
      "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274  \n",
      "      genero\n",
      "0  Masculino\n",
      "1  Masculino\n",
      "2  Masculino\n",
      "3  Masculino\n",
      "4  Masculino\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[297   4]\n",
      " [  8 325]]\n",
      "\n",
      "Precisión Global:\n",
      "0.9810725552050473\n",
      "\n",
      "Error Global:\n",
      "0.018927444794952675\n",
      "\n",
      "Precisión por categoría:\n",
      "   Femenino  Masculino\n",
      "0  0.986711   0.975976\n",
      "\n",
      "Precision Positiva (PP):\n",
      "0.975975975975976\n",
      "\n",
      "Precision Negativa (PN):\n",
      "0.9867109634551495\n",
      "\n",
      "Falsos Positivos(FP):\n",
      "0.013289036544850474\n",
      "\n",
      "Falsos Negativos (FN):\n",
      "0.024024024024024038\n",
      "\n",
      "Asertividad Positiva (AP):\n",
      "0.9878419452887538\n",
      "\n",
      "Asertividad Negativa (NP):\n",
      "0.9737704918032787\n"
     ]
    }
   ],
   "source": [
    "##Bosques\n",
    "X = datos.iloc[:,:20] \n",
    "print(X.head())\n",
    "y = datos.iloc[:,20:21] \n",
    "print(y.head())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "\n",
    "instancia_bosque = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "\n",
    "instancia_bosque.fit(X_train,y_train.iloc[:,0].values)\n",
    "prediccion = instancia_bosque.predict(X_test)\n",
    "MC = confusion_matrix(y_test, prediccion)\n",
    "indices = indices_general(MC,list(np.unique(y)))\n",
    "for k in indices:\n",
    "    print(\"\\n%s:\\n%s\"%(k,str(indices[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rzamoram\\Documents\\Machine Learning\\Métodos Supervisados con Python\\Clase 01\n",
      "(3168, 21)\n",
      "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
      "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
      "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
      "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
      "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
      "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
      "\n",
      "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
      "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
      "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
      "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
      "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
      "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
      "\n",
      "     maxfun   meandom    mindom    maxdom   dfrange   modindx     genero  \n",
      "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000  Masculino  \n",
      "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632  Masculino  \n",
      "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512  Masculino  \n",
      "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119  Masculino  \n",
      "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274  Masculino  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  genero    3168 non-null   object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ConsensoPropio at 0x1ff8a7506c8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pasada = os.getcwd()\n",
    "os.chdir(\"C:/Users/rzamoram/Documents/Machine Learning/Métodos Supervisados con Python/Clase 01\")\n",
    "print(os.getcwd())\n",
    "dataset = pd.read_csv('voces.csv',delimiter=',',decimal=\".\")\n",
    "print(dataset.shape)\n",
    "print(dataset.head())\n",
    "print(dataset.info())\n",
    "\n",
    "ConsensoPropio(dataset,10,dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forrest predice un 0.9810725552050473 correctamente, dada esta estimacion y viendo que con consenso propio se predice con la clase programada 0.990 con kvecinos, 0.891 con arboles, 0.889 en xgboosting y 0.127 en ada boosting. RandomForrest estimado con el algoritmo de python resulta mejor estimacion para el caso de voces."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
